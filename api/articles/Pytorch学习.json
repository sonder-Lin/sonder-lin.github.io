{"title":"Pytorch学习","uid":"c723f7d5a5457cbc1c88bbea11b3a805","slug":"Pytorch学习","date":"2024-01-31T05:51:09.000Z","updated":"2024-09-02T13:02:10.141Z","comments":true,"path":"api/articles/Pytorch学习.json","keywords":null,"cover":[],"content":"<h1 id=\"Pytorch学习\"><a href=\"#Pytorch学习\" class=\"headerlink\" title=\"Pytorch学习\"></a>Pytorch学习</h1><h3 id=\"数据操作\"><a href=\"#数据操作\" class=\"headerlink\" title=\"数据操作\"></a>数据操作</h3><p>tensor为torch中的一个数据结构，可以参与运算，称为张量，即多个数值组成的数组，可能有多个维度</p>\n<div class=\"language-python\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">python</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #292D3E\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">import</span><span style=\"color: #BABED8\"> torch</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">arrange</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">3</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\">  </span><span style=\"color: #676E95; font-style: italic\">#生成一个从0开始,长度为3的一维tensor</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">Out</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #F78C6C\">2</span><span style=\"color: #89DDFF\">])</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">shape</span><span style=\"color: #BABED8\">                </span><span style=\"color: #676E95; font-style: italic\">#查看tensor的形状</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">Out</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\">torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">Size</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">3</span><span style=\"color: #89DDFF\">])</span><span style=\"color: #BABED8\">    </span><span style=\"color: #676E95; font-style: italic\">#形状为：一维、长度为3</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">X</span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\">x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">reshape</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">3</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #F78C6C\">4</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\">       </span><span style=\"color: #676E95; font-style: italic\">#改变一个tensor的形状 改为二维的3x4矩阵</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">Out</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([[],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">       ...</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">            </span><span style=\"color: #676E95; font-style: italic\">#一个二维矩阵</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">           </span><span style=\"color: #89DDFF\">])</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #BABED8\">torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">cat</span><span style=\"color: #89DDFF\">((</span><span style=\"color: #82AAFF\">tensor1</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">tensor2</span><span style=\"color: #89DDFF\">),</span><span style=\"color: #BABED8; font-style: italic\">dim</span><span style=\"color: #89DDFF\">=</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">/</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\">       </span><span style=\"color: #676E95; font-style: italic\">#按行或按列 合并tensor</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#torch的广播机制</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">当两个tensor维度相同，但形状不一致进行运算时，两者从低到高扩展然后进行运算</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#torch的原地操作（以节省内存）</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">Z </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">zeros_like</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">Y</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\">   </span><span style=\"color: #676E95; font-style: italic\">#形状与Y一致，但初值为全0</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">print</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #89DDFF\">'</span><span style=\"color: #C3E88D\">id(Z):</span><span style=\"color: #89DDFF\">'</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> id</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">Z</span><span style=\"color: #89DDFF\">))</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">Z</span><span style=\"color: #89DDFF\">[:]</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> X </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> Y</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">print</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #89DDFF\">'</span><span style=\"color: #C3E88D\">id(Z):</span><span style=\"color: #89DDFF\">'</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> id</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">Z</span><span style=\"color: #89DDFF\">))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">id</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">Z</span><span style=\"color: #89DDFF\">):</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">140327634811696</span><span style=\"color: #BABED8\">             </span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">id</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">Z</span><span style=\"color: #89DDFF\">):</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">140327634811696</span><span style=\"color: #BABED8\">            </span><span style=\"color: #676E95; font-style: italic\">#运算后地址不变，成功原地操作</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#对于可变对象，如列表、集合、字典等</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">X </span><span style=\"color: #89DDFF\">+=</span><span style=\"color: #BABED8\"> Y 不等同于 X </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> X </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> Y</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">前者为原地操作，后者创建了新的对象（浪费了内存）</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">对于不可变对象 两者等同</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#torch与numpy</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">arrange</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">3</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x为一个tensor对象</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">A </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">numpy</span><span style=\"color: #89DDFF\">()</span><span style=\"color: #BABED8\">  </span><span style=\"color: #676E95; font-style: italic\">#将一个tensor对象转换为numpy中的ndarray对象</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">B </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">A</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\">  </span><span style=\"color: #676E95; font-style: italic\">#将一个ndarray对象转换为tensor对象</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #BABED8\">a </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">3.5</span><span style=\"color: #89DDFF\">])</span><span style=\"color: #BABED8\">   </span><span style=\"color: #676E95; font-style: italic\">#创建一个一维的 大小为1 的张量</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">a</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> a</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">item</span><span style=\"color: #89DDFF\">(),</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">float</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">a</span><span style=\"color: #89DDFF\">),</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">int</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">a</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\">    </span><span style=\"color: #676E95; font-style: italic\">#转换为python中的标量</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">output</span><span style=\"color: #89DDFF\">:(</span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">3.5000</span><span style=\"color: #89DDFF\">]),</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">3.5</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">3.5</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">3</span><span style=\"color: #89DDFF\">)</span></span></code></pre></div><h3 id=\"线性代数\"><a href=\"#线性代数\" class=\"headerlink\" title=\"线性代数\"></a>线性代数</h3><p>利用代码实现一些线代中的运算</p>\n<div class=\"language-python\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">python</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #292D3E\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">import</span><span style=\"color: #BABED8\"> torch</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">A </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">arange</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">20</span><span style=\"color: #89DDFF\">).</span><span style=\"color: #82AAFF\">reshape</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">5</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">4</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\">     </span><span style=\"color: #676E95; font-style: italic\">#初始化 5x4矩阵</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">A</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">2</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">3</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">4</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">5</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">6</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">7</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">8</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">9</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">10</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">11</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">12</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">13</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">14</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">15</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">16</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">17</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">18</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">19</span><span style=\"color: #89DDFF\">]])</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">A</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">T</span><span style=\"color: #BABED8\">                                    </span><span style=\"color: #676E95; font-style: italic\">#获取其转置</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">4</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">8</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">12</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">16</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">5</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">9</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">13</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">17</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">2</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">6</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">10</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">14</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">18</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">3</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">7</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">11</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">15</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">19</span><span style=\"color: #89DDFF\">]])</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#矩阵加法</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">A </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">arange</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">20</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #BABED8; font-style: italic\">dtype</span><span style=\"color: #89DDFF\">=</span><span style=\"color: #82AAFF\">torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">float32</span><span style=\"color: #89DDFF\">).</span><span style=\"color: #82AAFF\">reshape</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">5</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">4</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">B </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> A</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">clone</span><span style=\"color: #89DDFF\">()</span><span style=\"color: #BABED8\">  </span><span style=\"color: #676E95; font-style: italic\"># 通过分配新内存，将A的一个副本分配给B</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">A</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> A </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> B</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">2</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">3</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">         </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">4</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">5</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">6</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">7</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">         </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">8</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">9</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">10</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">11</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">         </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">12</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">13</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">14</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">15</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">         </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">16</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">17</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">18</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">19</span><span style=\"color: #89DDFF\">.]]),</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">2</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">4</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">6</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">         </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">8</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">10</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">12</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">14</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">         </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">16</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">18</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">20</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">22</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">         </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">24</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">26</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">28</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">30</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">         </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">32</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">34</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">36</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">38</span><span style=\"color: #89DDFF\">.]]))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #BABED8\">A </span><span style=\"color: #89DDFF\">*</span><span style=\"color: #BABED8\"> B                        </span><span style=\"color: #676E95; font-style: italic\">#按元素乘法  </span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([[</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">   </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">   </span><span style=\"color: #F78C6C\">4</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">   </span><span style=\"color: #F78C6C\">9</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">16</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">25</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">36</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">49</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">64</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">81</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">100</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">121</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">144</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">169</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">196</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">225</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">256</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">289</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">324</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">361</span><span style=\"color: #89DDFF\">.]])</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#降维操作</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">arange</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">4</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #BABED8; font-style: italic\">dtype</span><span style=\"color: #89DDFF\">=</span><span style=\"color: #82AAFF\">torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">float32</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">sum</span><span style=\"color: #89DDFF\">()</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">2</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">3</span><span style=\"color: #89DDFF\">.]),</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">6</span><span style=\"color: #89DDFF\">.))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#默认情况下，调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量。 我们还可以指定张量沿哪一个轴来通过求和降低维度。以矩阵为例，为了通过求和所有行的元素来降维（轴0），可以在调用函数时指定axis=0。 由于输入矩阵沿0轴降维以生成输出向量，因此输入轴0的维数在输出形状中消失。</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">A_sum_axis0 </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> A</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">sum</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #BABED8; font-style: italic\">axis</span><span style=\"color: #89DDFF\">=</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">A_sum_axis0</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> A_sum_axis0</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">shape</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">40</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">45</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">50</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">55</span><span style=\"color: #89DDFF\">.]),</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">Size</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">4</span><span style=\"color: #89DDFF\">]))</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">A_sum_axis1 </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> A</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">sum</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #BABED8; font-style: italic\">axis</span><span style=\"color: #89DDFF\">=</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">A_sum_axis1</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> A_sum_axis1</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">shape</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">6</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">22</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">38</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">54</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">70</span><span style=\"color: #89DDFF\">.]),</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">Size</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">5</span><span style=\"color: #89DDFF\">]))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#求平均值</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">A</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">mean</span><span style=\"color: #89DDFF\">(),</span><span style=\"color: #BABED8\"> A</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">sum</span><span style=\"color: #89DDFF\">()</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">/</span><span style=\"color: #BABED8\"> A</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">numel</span><span style=\"color: #89DDFF\">()</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">9.5000</span><span style=\"color: #89DDFF\">),</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">9.5000</span><span style=\"color: #89DDFF\">))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#点积</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">y </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">ones</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">4</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #BABED8; font-style: italic\">dtype</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #82AAFF\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">float32</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> y</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">dot</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">x</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> y</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">2</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">3</span><span style=\"color: #89DDFF\">.]),</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">.]),</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">6</span><span style=\"color: #89DDFF\">.))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#矩阵-向量积</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">A</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">shape</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">shape</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">mv</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">A</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> x</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">(</span><span style=\"color: #BABED8\">torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">Size</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">5</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">4</span><span style=\"color: #89DDFF\">]),</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">Size</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">4</span><span style=\"color: #89DDFF\">]),</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">14</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">38</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">62</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">86</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">110</span><span style=\"color: #89DDFF\">.]))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#矩阵-矩阵乘法</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">B </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">ones</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">4</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">3</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">mm</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">A</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> B</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">6</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">6</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">6</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">22</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">22</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">22</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">38</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">38</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">38</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">54</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">54</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">54</span><span style=\"color: #89DDFF\">.],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">70</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">70</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">70</span><span style=\"color: #89DDFF\">.]])</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#范数</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">u </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">3.0</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">-</span><span style=\"color: #F78C6C\">4.0</span><span style=\"color: #89DDFF\">])</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">norm</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">u</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\">             </span><span style=\"color: #676E95; font-style: italic\">#L2范数：所有元素平方和的平方根</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">5</span><span style=\"color: #89DDFF\">.)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #BABED8\">torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">abs</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">u</span><span style=\"color: #89DDFF\">).</span><span style=\"color: #82AAFF\">sum</span><span style=\"color: #89DDFF\">()</span><span style=\"color: #BABED8\">        </span><span style=\"color: #676E95; font-style: italic\">#L1范数：所有元素的绝对值求和</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">7</span><span style=\"color: #89DDFF\">.)</span></span></code></pre></div><h3 id=\"微积分\"><a href=\"#微积分\" class=\"headerlink\" title=\"微积分\"></a>微积分</h3><p>对矩阵进行诸如求导数等运算</p>\n<img src=\"https://raw.githubusercontent.com/sonder-Lin/Mypic/img/img/image-20240831192411308.png\" alt=\"image-20240831192411308\" style=\"zoom: 50%;\">\n\n<p><strong>分子布局符号，以分子优先</strong></p>\n<p><strong>对矩阵求导后的形状：</strong></p>\n<img src=\"https://raw.githubusercontent.com/sonder-Lin/Mypic/img/img/image-20240831192546896.png\" alt=\"image-20240831192546896\" style=\"zoom: 33%;\">\n\n<p><strong>计算图理论</strong></p>\n<img src=\"https://raw.githubusercontent.com/sonder-Lin/Mypic/img/img/image-20240831194737540.png\" alt=\"image-20240831194737540\" style=\"zoom: 33%;\">\n\n<p><strong>由此引出反向传递：</strong></p>\n<img src=\"https://raw.githubusercontent.com/sonder-Lin/Mypic/img/img/image-20240831195158452.png\" alt=\"image-20240831195158452\" style=\"zoom: 33%;\">\n\n<img src=\"https://raw.githubusercontent.com/sonder-Lin/Mypic/img/img/image-20240831195435665.png\" alt=\"image-20240831195435665\" style=\"zoom: 33%;\">\n\n<img src=\"https://raw.githubusercontent.com/sonder-Lin/Mypic/img/img/image-20240831195501570.png\" alt=\"image-20240831195501570\" style=\"zoom: 33%;\">\n\n<p><strong>可以发现反向传播需要利用正向传播求导的中间结果，空间复杂度较高（因此比较占用GPU资源），计算复杂度与正向传播的代价类似，但正向传播不需要存储中间结果，空间复杂度较低，但正是由于其不存储中间结果，因此导致每次都需要重新计算，导致在实际使用时的时间复杂度太高。</strong></p>\n<h4 id=\"自动求导\"><a href=\"#自动求导\" class=\"headerlink\" title=\"自动求导\"></a>自动求导</h4><div class=\"language-python\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">python</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #292D3E\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF; font-style: italic\">import</span><span style=\"color: #BABED8\"> torch</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">arange</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">4.0</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">2</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">3</span><span style=\"color: #89DDFF\">.])</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">requires_grad_</span><span style=\"color: #89DDFF\">(True)</span><span style=\"color: #BABED8\">  </span><span style=\"color: #676E95; font-style: italic\"># 等价于x=torch.arange(4.0,requires_grad=True)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">grad</span><span style=\"color: #BABED8\">  </span><span style=\"color: #676E95; font-style: italic\"># 默认值是None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\"># 现在计算y</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">y </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">2</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">*</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">dot</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">x</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> x</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\">         </span><span style=\"color: #676E95; font-style: italic\">#内积，因此y=2x^2</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">y</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">28</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #BABED8; font-style: italic\">grad_fn</span><span style=\"color: #89DDFF\">=&lt;</span><span style=\"color: #82AAFF\">MulBackward0</span><span style=\"color: #89DDFF\">&gt;)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#接下来，通过调用反向传播函数来自动计算y关于x每个分量的梯度，并打印这些梯度。</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">y</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">backward</span><span style=\"color: #89DDFF\">()</span><span style=\"color: #BABED8\">      </span><span style=\"color: #676E95; font-style: italic\">#反向传播进行求导</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">grad</span><span style=\"color: #BABED8\">            </span><span style=\"color: #676E95; font-style: italic\">#直接访问y关于x的导数</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">grad</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">==</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">4</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">*</span><span style=\"color: #BABED8\"> x</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([True,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">True,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">True,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">True])</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">grad</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">zero_</span><span style=\"color: #89DDFF\">()</span><span style=\"color: #BABED8\">         </span><span style=\"color: #676E95; font-style: italic\"># 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #BABED8\">y </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">sum</span><span style=\"color: #89DDFF\">()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">y</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">backward</span><span style=\"color: #89DDFF\">()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">grad</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">.,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">.])</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#在深度学习中 一般仅对标量进行求导</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\"># 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\"># 本例只想求偏导数的和，所以传递一个1的梯度是合适的</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">grad</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">zero_</span><span style=\"color: #89DDFF\">()</span><span style=\"color: #BABED8\">     </span><span style=\"color: #676E95; font-style: italic\">#清空梯度</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">y </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> x </span><span style=\"color: #89DDFF\">*</span><span style=\"color: #BABED8\"> x</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\"># 等价于y.backward(torch.ones(len(x)))</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">y</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">sum</span><span style=\"color: #89DDFF\">().</span><span style=\"color: #82AAFF\">backward</span><span style=\"color: #89DDFF\">()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">grad</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">grad</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">zero_</span><span style=\"color: #89DDFF\">()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">y </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> x </span><span style=\"color: #89DDFF\">*</span><span style=\"color: #BABED8\"> x</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">u </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> y</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">detach</span><span style=\"color: #89DDFF\">()</span><span style=\"color: #BABED8\">     </span><span style=\"color: #676E95; font-style: italic\">#当做常数</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">z </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> u </span><span style=\"color: #89DDFF\">*</span><span style=\"color: #BABED8\"> x   </span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #BABED8\">z</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">sum</span><span style=\"color: #89DDFF\">().</span><span style=\"color: #82AAFF\">backward</span><span style=\"color: #89DDFF\">()</span><span style=\"color: #BABED8\">      </span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">x</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">grad</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">==</span><span style=\"color: #BABED8\"> u        </span><span style=\"color: #676E95; font-style: italic\">#求导时也将其当做了常数</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([True,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">True,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">True,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">True])</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#控制流的梯度计算</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">f</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #BABED8; font-style: italic\">a</span><span style=\"color: #89DDFF\">):</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    b </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> a </span><span style=\"color: #89DDFF\">*</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">2</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">while</span><span style=\"color: #BABED8\"> b</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">norm</span><span style=\"color: #89DDFF\">()</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&lt;</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">1000</span><span style=\"color: #89DDFF\">:</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">        b </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> b </span><span style=\"color: #89DDFF\">*</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">2</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">if</span><span style=\"color: #BABED8\"> b</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">sum</span><span style=\"color: #89DDFF\">()</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&gt;</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">:</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">        c </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> b</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">else</span><span style=\"color: #89DDFF\">:</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">        c </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">100</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">*</span><span style=\"color: #BABED8\"> b</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">return</span><span style=\"color: #BABED8\"> c</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #BABED8\">a </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">randn</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #BABED8; font-style: italic\">size</span><span style=\"color: #89DDFF\">=(),</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #BABED8; font-style: italic\">requires_grad</span><span style=\"color: #89DDFF\">=True)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">d </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">f</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">a</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">d</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">backward</span><span style=\"color: #89DDFF\">()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">a</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">grad</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">==</span><span style=\"color: #BABED8\"> d </span><span style=\"color: #89DDFF\">/</span><span style=\"color: #BABED8\"> a</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">(True)</span></span></code></pre></div><h3 id=\"线性神经网络\"><a href=\"#线性神经网络\" class=\"headerlink\" title=\"线性神经网络\"></a>线性神经网络</h3><h4 id=\"线性回归\"><a href=\"#线性回归\" class=\"headerlink\" title=\"线性回归\"></a>线性回归</h4><p>​\t\t线性回归是指目标可以表示为特征的加权和，如下面的式子，其中w代表权重，x代表某样本数据的各特征，b偏移量（所有特征为0时的值）：<br><mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"26.517ex\" height=\"2.296ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -810 11720.4 1015\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(300.6,16) translate(-250 0)\"><path data-c=\"5E\" d=\"M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(767.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(1823.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D464\" d=\"M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(749,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(2976.1,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(4206.9,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5207.1,0)\"><path data-c=\"2026\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(6601.3,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(7601.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D464\" d=\"M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(749,-150) scale(0.707)\"><path data-c=\"1D451\" d=\"M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z\"></path></g></g><g data-mml-node=\"msub\" transform=\"translate(8768.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"1D451\" d=\"M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(10013.2,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(11013.4,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(11442.4,0)\"><path data-c=\"2E\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g></g></g></svg></mjx-container><br>​       我们可以用点积形式来简洁地表达模型：其中向量x对应于单个数据样本的特征<br><mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"13.177ex\" height=\"2.467ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -885.3 5824.1 1090.3\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(300.6,16) translate(-250 0)\"><path data-c=\"5E\" d=\"M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(767.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(1823.6,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(864,413) scale(0.707)\"><path data-c=\"22A4\" d=\"M55 642T55 648T59 659T66 666T71 668H708Q723 660 723 648T708 628H409V15Q402 2 391 0Q387 0 384 1T379 3T375 6T373 9T371 13T369 16V628H71Q70 628 67 630T59 637Z\"></path></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(3287.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D431\" d=\"M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(4116.9,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5117.1,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5546.1,0)\"><path data-c=\"2E\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g></g></g></svg></mjx-container><br>​\t\t对于特征集合X，预测值<mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.452ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"6.92ex\" height=\"2.29ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -812 3058.8 1012\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D432\" d=\"M84 -102Q84 -110 87 -119T102 -138T133 -149Q148 -148 162 -143T186 -131T206 -114T222 -95T234 -76T243 -59T249 -45T252 -37L269 0L96 382H26V444H34Q49 441 146 441Q252 441 270 444H279V382H255Q232 382 232 380L337 151L442 382H394V444H401Q413 441 495 441Q568 441 574 444H580V382H510L406 152Q298 -84 297 -87Q269 -139 225 -169T131 -200Q85 -200 54 -172T23 -100Q23 -64 44 -50T87 -35Q111 -35 130 -50T152 -92V-100H84V-102Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(303.5,18) translate(-250 0)\"><path data-c=\"5E\" d=\"M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(884.8,0)\"><path data-c=\"2208\" d=\"M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(1829.6,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"211D\" d=\"M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(755,363) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></g></svg></mjx-container>可以通过矩阵-向量乘法表示为：其中，X的每一行是一个样本，每一列是一种特征。<br><mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.452ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"11.973ex\" height=\"2.29ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -812 5292 1012\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D432\" d=\"M84 -102Q84 -110 87 -119T102 -138T133 -149Q148 -148 162 -143T186 -131T206 -114T222 -95T234 -76T243 -59T249 -45T252 -37L269 0L96 382H26V444H34Q49 441 146 441Q252 441 270 444H279V382H255Q232 382 232 380L337 151L442 382H394V444H401Q413 441 495 441Q568 441 574 444H580V382H510L406 152Q298 -84 297 -87Q269 -139 225 -169T131 -200Q85 -200 54 -172T23 -100Q23 -64 44 -50T87 -35Q111 -35 130 -50T152 -92V-100H84V-102Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(303.5,18) translate(-250 0)\"><path data-c=\"5E\" d=\"M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z\"></path></g></g></g></g><g data-mml-node=\"mo\" transform=\"translate(884.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1940.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(2809.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(3862.8,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4863,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g></g></g></svg></mjx-container><br>​\t\t在开始寻找最好的模型参数（model parameters）<mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.62ex\" height=\"1.027ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -443 716 454\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D464\" d=\"M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z\"></path></g></g></g></svg></mjx-container>和<mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.025ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"0.971ex\" height=\"1.595ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -694 429 705\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g></g></g></svg></mjx-container>之前， 我们还需要两个东西：一种模型质量的度量方式；一种能够更新模型以提高模型预测质量的方法。</p>\n<h4 id=\"损失函数\"><a href=\"#损失函数\" class=\"headerlink\" title=\"损失函数\"></a><strong>损失函数</strong></h4><p>​\t在我们开始考虑如何用模型拟合（fit）数据之前，我们需要确定一个拟合程度的度量。<br>​\t损失函数（loss function）能够量化目标的实际值与预测值之间的差距。 通常我们会选择非负数作为损失，且数值越小表示损失越小，完美预测时的损失为0。 回归问题中最常用的损失函数是平方误差函数。当样本i的预测值为<mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.093ex\" height=\"2.598ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -943.3 1367.1 1148.3\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(300.6,16) translate(-250 0)\"><path data-c=\"5E\" d=\"M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z\"></path></g></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(523,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(734,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></g></g></svg></mjx-container>，其相应的真实标签为<mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.464ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"3.093ex\" height=\"2.598ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -943.3 1367.1 1148.3\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(523,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(734,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></g></g></svg></mjx-container>时， 平方误差可以定义为以下公式：<br><mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -1.552ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"26.689ex\" height=\"4.601ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -1347.5 11796.5 2033.5\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"mi\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(331,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(734,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(1175.1,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1564.1,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2395.1,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2839.7,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3268.7,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3935.5,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mfrac\" transform=\"translate(4991.3,0)\"><g data-mml-node=\"mn\" transform=\"translate(220,676)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(220,-686)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><rect width=\"700\" height=\"60\" x=\"120\" y=\"220\"></rect></g><g data-mml-node=\"msup\" transform=\"translate(5931.3,0)\"><g data-mml-node=\"mrow\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"28\" d=\"M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(597,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mover\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(300.6,16) translate(-250 0)\"><path data-c=\"5E\" d=\"M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z\"></path></g></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(523,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(734,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(2186.3,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(3186.5,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(523,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(734,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(4553.6,0) translate(0 -0.5)\"><path data-c=\"29\" d=\"M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z\"></path></g></g><g data-mml-node=\"mn\" transform=\"translate(5183.6,876.6) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(11518.5,0)\"><path data-c=\"2E\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g></g></g></svg></mjx-container><br>   为了度量模型在整个数据集上的质量，我们需计算在训练集n个样本上的损失均值（也等价于求和）。<br><mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -2.819ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"56.925ex\" height=\"6.354ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -1562.5 25160.9 2808.5\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43F\" d=\"M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(681,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1070,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1901,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2345.7,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2774.7,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3441.4,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mfrac\" transform=\"translate(4497.2,0)\"><g data-mml-node=\"mn\" transform=\"translate(270,676)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(220,-686)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><rect width=\"800\" height=\"60\" x=\"120\" y=\"220\"></rect></g><g data-mml-node=\"munderover\" transform=\"translate(5703.9,0)\"><g data-mml-node=\"mo\"><path data-c=\"2211\" d=\"M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(148.2,-1087.9) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(345,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1123,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(509.9,1150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g><g data-mml-node=\"msup\" transform=\"translate(7314.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(331,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(734,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(8489.6,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(8878.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(9709.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10154.3,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(10583.3,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(11250.1,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mfrac\" transform=\"translate(12305.9,0)\"><g data-mml-node=\"mn\" transform=\"translate(270,676)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(220,-686)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><rect width=\"800\" height=\"60\" x=\"120\" y=\"220\"></rect></g><g data-mml-node=\"munderover\" transform=\"translate(13512.5,0)\"><g data-mml-node=\"mo\"><path data-c=\"2211\" d=\"M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(148.2,-1087.9) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(345,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(1123,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(509.9,1150) scale(0.707)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g></g><g data-mml-node=\"mfrac\" transform=\"translate(15123.2,0)\"><g data-mml-node=\"mn\" transform=\"translate(220,676)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(220,-686)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><rect width=\"700\" height=\"60\" x=\"120\" y=\"220\"></rect></g><g data-mml-node=\"msup\" transform=\"translate(16063.2,0)\"><g data-mml-node=\"mrow\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"28\" d=\"M180 96T180 250T205 541T266 770T353 944T444 1069T527 1150H555Q561 1144 561 1141Q561 1137 545 1120T504 1072T447 995T386 878T330 721T288 513T272 251Q272 133 280 56Q293 -87 326 -209T399 -405T475 -531T536 -609T561 -640Q561 -643 555 -649H527Q483 -612 443 -568T353 -443T266 -270T205 -41Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(597,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(864,413) scale(0.707)\"><path data-c=\"22A4\" d=\"M55 642T55 648T59 659T66 666T71 668H708Q723 660 723 648T708 628H409V15Q402 2 391 0Q387 0 384 1T379 3T375 6T373 9T371 13T369 16V628H71Q70 628 67 630T59 637Z\"></path></g></g><g data-mml-node=\"msup\" transform=\"translate(2061.1,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D431\" d=\"M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z\"></path></g></g><g data-mml-node=\"TeXAtom\" transform=\"translate(640,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(734,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(3767.4,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4767.7,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5418.9,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(6419.1,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(523,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(734,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(7786.2,0) translate(0 -0.5)\"><path data-c=\"29\" d=\"M35 1138Q35 1150 51 1150H56H69Q113 1113 153 1069T243 944T330 771T391 541T416 250T391 -40T330 -270T243 -443T152 -568T69 -649H56Q43 -649 39 -647T35 -637Q65 -607 110 -548Q283 -316 316 56Q324 133 324 251Q324 368 316 445Q278 877 48 1123Q36 1137 35 1138Z\"></path></g></g><g data-mml-node=\"mn\" transform=\"translate(8416.2,876.6) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(24882.9,0)\"><path data-c=\"2E\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g></g></g></svg></mjx-container><br>   在训练模型时，我们希望寻找一组参数（w∗,b∗）， 这组参数能最小化在所有训练样本上的总损失。如下式：<br><mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -2.491ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"24.499ex\" height=\"4.188ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 10828.7 1850.9\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(864,413) scale(0.707)\"><path data-c=\"2217\" d=\"M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1267.6,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(1712.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(462,413) scale(0.707)\"><path data-c=\"2217\" d=\"M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(2855.6,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"munder\" transform=\"translate(3911.3,0)\"><g data-mml-node=\"mi\"><path data-c=\"61\" d=\"M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z\"></path><path data-c=\"72\" d=\"M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z\" transform=\"translate(500,0)\"></path><path data-c=\"67\" d=\"M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z\" transform=\"translate(892,0)\"></path><path data-c=\"6D\" d=\"M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z\" transform=\"translate(1392,0)\"></path><path data-c=\"69\" d=\"M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z\" transform=\"translate(2225,0)\"></path><path data-c=\"6E\" d=\"M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z\" transform=\"translate(2503,0)\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(985.7,-863.7) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(831,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1109,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g></g></g><g data-mml-node=\"mtext\" transform=\"translate(7137,0)\"><path data-c=\"A0\" d=\"\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7387,0)\"><path data-c=\"1D43F\" d=\"M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(8068,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(8457,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(9288,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9732.7,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(10161.7,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(10550.7,0)\"><path data-c=\"2E\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g></g></g></svg></mjx-container><br>   我们的预测问题是最小化<mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.564ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"10.231ex\" height=\"2.564ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -883.9 4522 1133.4\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(278,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D432\" d=\"M84 -102Q84 -110 87 -119T102 -138T133 -149Q148 -148 162 -143T186 -131T206 -114T222 -95T234 -76T243 -59T249 -45T252 -37L269 0L96 382H26V444H34Q49 441 146 441Q252 441 270 444H279V382H255Q232 382 232 380L337 151L442 382H394V444H401Q413 441 495 441Q568 441 574 444H580V382H510L406 152Q298 -84 297 -87Q269 -139 225 -169T131 -200Q85 -200 54 -172T23 -100Q23 -64 44 -50T87 -35Q111 -35 130 -50T152 -92V-100H84V-102Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1107.2,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(2107.4,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(2976.4,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"msup\" transform=\"translate(3807.4,0)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(311,413) scale(0.707)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g></g></g></g></svg></mjx-container>，由于其为凸函数，即在损失平面上只有一个临界点，所以存在参数的解析解。因此将损失关于w的导数设为0，得到解析解：</p>\n<p><mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"20.643ex\" height=\"2.569ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -885.3 9124 1135.3\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"msup\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(864,413) scale(0.707)\"><path data-c=\"2217\" d=\"M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1545.3,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2601.1,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"msup\" transform=\"translate(2990.1,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(902,413) scale(0.707)\"><path data-c=\"22A4\" d=\"M55 642T55 648T59 659T66 666T71 668H708Q723 660 723 648T708 628H409V15Q402 2 391 0Q387 0 384 1T379 3T375 6T373 9T371 13T369 16V628H71Q70 628 67 630T59 637Z\"></path></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(4492.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g><g data-mml-node=\"msup\" transform=\"translate(5361.2,0)\"><g data-mml-node=\"mo\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(422,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(778,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g><g data-mml-node=\"msup\" transform=\"translate(6736.9,0)\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D417\" d=\"M327 0Q306 3 174 3Q52 3 43 0H33V62H98L162 63L360 333L157 624H48V686H59Q80 683 217 683Q368 683 395 686H408V624H335L393 540L452 458L573 623Q573 624 528 624H483V686H494Q515 683 646 683Q769 683 778 686H787V624H658L575 511Q493 398 493 397L508 376Q522 356 553 312T611 229L727 62H835V0H824Q803 3 667 3Q516 3 489 0H476V62H513L549 63L401 274L247 63Q247 62 292 62H338V0H327Z\"></path></g></g><g data-mml-node=\"mi\" transform=\"translate(902,413) scale(0.707)\"><path data-c=\"22A4\" d=\"M55 642T55 648T59 659T66 666T71 668H708Q723 660 723 648T708 628H409V15Q402 2 391 0Q387 0 384 1T379 3T375 6T373 9T371 13T369 16V628H71Q70 628 67 630T59 637Z\"></path></g></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(8239,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D432\" d=\"M84 -102Q84 -110 87 -119T102 -138T133 -149Q148 -148 162 -143T186 -131T206 -114T222 -95T234 -76T243 -59T249 -45T252 -37L269 0L96 382H26V444H34Q49 441 146 441Q252 441 270 444H279V382H255Q232 382 232 380L337 151L442 382H394V444H401Q413 441 495 441Q568 441 574 444H580V382H510L406 152Q298 -84 297 -87Q269 -139 225 -169T131 -200Q85 -200 54 -172T23 -100Q23 -64 44 -50T87 -35Q111 -35 130 -50T152 -92V-100H84V-102Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(8846,0)\"><path data-c=\"2E\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g></g></g></svg></mjx-container><br>   像线性回归这样的简单问题存在解析解，但并不是所有的问题都存在解析解。解析解对问题的限制很严格，导致它无法广泛应用在深度学习里。</p>\n<h4 id=\"随机梯度下降\"><a href=\"#随机梯度下降\" class=\"headerlink\" title=\"随机梯度下降\"></a><strong>随机梯度下降</strong></h4><p>即使在我们无法得到解析解的情况下，我们仍然可以有效地训练模型。 在许多任务上，那些难以优化的模型效果要更好。 因此，弄清楚如何训练这些难以优化的模型是非常重要的。</p>\n<p>​\t\t本书中我们用到一种名为梯度下降（gradient descent）的方法， 这种方法几乎可以优化所有深度学习模型。 它通过不断地在损失函数递减的方向\t\t上更新参数来降低误差。</p>\n<p>​\t\t梯度下降最简单的用法是计算损失函数（数据集中所有样本的损失均值）关于模型参数的导数（在这里也可以称为梯度）。但实际中的执行可能会非常\t\t慢：因为在每一次更新参数之前，我们必须遍历整个数据集。 因此，我们通常会在每次需要计算更新的时候随机抽取一小批样本，这种变体叫做小批量\t\t随机梯度下降（minibatch stochastic gradient descent）。</p>\n<p>​       在每次迭代中，我们首先随机抽样一个小批量<mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.486ex\" height=\"1.645ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -705 657 727\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"42\" d=\"M304 342Q292 342 292 353Q292 372 323 391Q331 396 417 428T533 487Q563 512 563 555V562Q563 575 557 589T530 618T475 636Q429 636 396 613T330 539Q263 446 210 238Q196 183 173 120Q135 31 121 16Q108 1 85 -10T47 -22T32 -10Q32 -5 44 18T77 93T112 206Q135 296 154 395T182 550T191 615Q191 616 190 616Q188 616 179 611T157 601T131 594Q113 594 113 605Q113 623 144 644Q154 650 205 676T267 703Q277 705 279 705Q295 705 295 693Q295 686 288 635T278 575Q278 572 287 582Q336 635 402 669T540 704Q603 704 633 673T664 599Q664 559 638 523T580 462Q553 440 504 413L491 407L504 402Q566 381 596 338T627 244Q627 172 575 110T444 13T284 -22Q208 -22 158 28Q144 42 146 50Q150 67 178 85T230 103Q236 103 246 95T267 75T302 56T357 47Q436 47 486 93Q526 136 526 198V210Q526 228 518 249T491 292T436 330T350 345Q335 345 321 344T304 342Z\"></path></g></g></g></g></svg></mjx-container>，它是由固定数量的训练样本组成的。然后，我们计算小批量的平均损失关于模型参数的导数（也可以\t\t称为梯度）。最后，我们将梯度乘以一个预先确定的正数<mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.489ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.124ex\" height=\"1.489ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 497 658\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D702\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>（即学习率），并从当前参数的值中减掉，从而将参数沿着损失函数梯度的相反方向移动（损   \t\t失函数值下降最快的方向）。</p>\n<p>​\t\t用下面的数学公式来表示这一更新过程（<mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.05ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.281ex\" height=\"1.667ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -715 566 737\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"2202\" d=\"M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z\"></path></g></g></g></g></svg></mjx-container>表示偏导数）：<br><mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -2.814ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"39.278ex\" height=\"5.343ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -1118 17361.1 2361.8\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(389,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1220,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1664.7,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2093.7,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2760.4,0)\"><path data-c=\"2190\" d=\"M944 261T944 250T929 230H165Q167 228 182 216T211 189T244 152T277 96T303 25Q308 7 308 0Q308 -11 288 -11Q281 -11 278 -11T272 -7T267 2T263 21Q245 94 195 151T73 236Q58 242 55 247Q55 254 59 257T73 264Q121 283 158 314T215 375T247 434T264 480L267 497Q269 503 270 505T275 509T288 511Q308 511 308 500Q308 493 303 475Q293 438 278 406T246 352T215 315T185 287T165 270H929Q944 261 944 250Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4038.2,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(4427.2,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(5258.2,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5702.9,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(6131.9,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(6743.1,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mfrac\" transform=\"translate(7743.3,0)\"><g data-mml-node=\"mi\" transform=\"translate(578,676)\"><path data-c=\"1D702\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mrow\" transform=\"translate(220,-709.5)\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(278,0)\"><g data-mml-node=\"mi\"><path data-c=\"42\" d=\"M304 342Q292 342 292 353Q292 372 323 391Q331 396 417 428T533 487Q563 512 563 555V562Q563 575 557 589T530 618T475 636Q429 636 396 613T330 539Q263 446 210 238Q196 183 173 120Q135 31 121 16Q108 1 85 -10T47 -22T32 -10Q32 -5 44 18T77 93T112 206Q135 296 154 395T182 550T191 615Q191 616 190 616Q188 616 179 611T157 601T131 594Q113 594 113 605Q113 623 144 644Q154 650 205 676T267 703Q277 705 279 705Q295 705 295 693Q295 686 288 635T278 575Q278 572 287 582Q336 635 402 669T540 704Q603 704 633 673T664 599Q664 559 638 523T580 462Q553 440 504 413L491 407L504 402Q566 381 596 338T627 244Q627 172 575 110T444 13T284 -22Q208 -22 158 28Q144 42 146 50Q150 67 178 85T230 103Q236 103 246 95T267 75T302 56T357 47Q436 47 486 93Q526 136 526 198V210Q526 228 518 249T491 292T436 330T350 345Q335 345 321 344T304 342Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(935,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g></g><rect width=\"1413\" height=\"60\" x=\"120\" y=\"220\"></rect></g><g data-mml-node=\"munder\" transform=\"translate(9563,0)\"><g data-mml-node=\"mo\"><path data-c=\"2211\" d=\"M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(131.9,-1115.5) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mi\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(345,0)\"><path data-c=\"2208\" d=\"M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(1012,0)\"><g data-mml-node=\"mi\"><path data-c=\"42\" d=\"M304 342Q292 342 292 353Q292 372 323 391Q331 396 417 428T533 487Q563 512 563 555V562Q563 575 557 589T530 618T475 636Q429 636 396 613T330 539Q263 446 210 238Q196 183 173 120Q135 31 121 16Q108 1 85 -10T47 -22T32 -10Q32 -5 44 18T77 93T112 206Q135 296 154 395T182 550T191 615Q191 616 190 616Q188 616 179 611T157 601T131 594Q113 594 113 605Q113 623 144 644Q154 650 205 676T267 703Q277 705 279 705Q295 705 295 693Q295 686 288 635T278 575Q278 572 287 582Q336 635 402 669T540 704Q603 704 633 673T664 599Q664 559 638 523T580 462Q553 440 504 413L491 407L504 402Q566 381 596 338T627 244Q627 172 575 110T444 13T284 -22Q208 -22 158 28Q144 42 146 50Q150 67 178 85T230 103Q236 103 246 95T267 75T302 56T357 47Q436 47 486 93Q526 136 526 198V210Q526 228 518 249T491 292T436 330T350 345Q335 345 321 344T304 342Z\"></path></g></g></g></g><g data-mml-node=\"msub\" transform=\"translate(11173.7,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D715\" d=\"M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(564,-176.7) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(389,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(1220,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1498,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1927,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g><g data-mml-node=\"msup\" transform=\"translate(13425.3,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"TeXAtom\" transform=\"translate(331,413) scale(0.707)\" data-mjx-texclass=\"ORD\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(389,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(734,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g><g data-mml-node=\"mo\" transform=\"translate(14600.4,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(14989.4,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D430\" d=\"M624 444Q636 441 722 441Q797 441 800 444H805V382H741L593 11Q592 10 590 8T586 4T584 2T581 0T579 -2T575 -3T571 -3T567 -4T561 -4T553 -4H542Q525 -4 518 6T490 70Q474 110 463 137L415 257L367 137Q357 111 341 72Q320 17 313 7T289 -4H277Q259 -4 253 -2T238 11L90 382H25V444H32Q47 441 140 441Q243 441 261 444H270V382H222L310 164L382 342L366 382H303V444H310Q322 441 407 441Q508 441 523 444H531V382H506Q481 382 481 380Q482 376 529 259T577 142L674 382H617V444H624Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(15820.4,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(16265.1,0)\"><path data-c=\"1D44F\" d=\"M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(16694.1,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(17083.1,0)\"><path data-c=\"2E\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path></g></g></g></svg></mjx-container><br>​\t\t总结一下，算法的步骤如下： </p>\n<p>​\t\t（1）初始化模型参数的值，如随机初始化； （2）从数据集中随机抽取小批量样本且在负梯度的方向上更新参数，并不断迭代这一步骤。</p>\n<p>​\t  其中<mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.564ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"2.744ex\" height=\"2.26ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -749.5 1213 999\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\" transform=\"translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g><g data-mml-node=\"TeXAtom\" data-mjx-texclass=\"ORD\" transform=\"translate(278,0)\"><g data-mml-node=\"mi\"><path data-c=\"42\" d=\"M304 342Q292 342 292 353Q292 372 323 391Q331 396 417 428T533 487Q563 512 563 555V562Q563 575 557 589T530 618T475 636Q429 636 396 613T330 539Q263 446 210 238Q196 183 173 120Q135 31 121 16Q108 1 85 -10T47 -22T32 -10Q32 -5 44 18T77 93T112 206Q135 296 154 395T182 550T191 615Q191 616 190 616Q188 616 179 611T157 601T131 594Q113 594 113 605Q113 623 144 644Q154 650 205 676T267 703Q277 705 279 705Q295 705 295 693Q295 686 288 635T278 575Q278 572 287 582Q336 635 402 669T540 704Q603 704 633 673T664 599Q664 559 638 523T580 462Q553 440 504 413L491 407L504 402Q566 381 596 338T627 244Q627 172 575 110T444 13T284 -22Q208 -22 158 28Q144 42 146 50Q150 67 178 85T230 103Q236 103 246 95T267 75T302 56T357 47Q436 47 486 93Q526 136 526 198V210Q526 228 518 249T491 292T436 330T350 345Q335 345 321 344T304 342Z\"></path></g></g><g data-mml-node=\"mo\" transform=\"translate(935,0) translate(0 -0.5)\"><path data-c=\"7C\" d=\"M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z\"></path></g></g></g></svg></mjx-container>（batch_size）表示每个小批量中的样本数量，称为批量大小，<mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.489ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1.124ex\" height=\"1.489ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -442 497 658\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D702\" d=\"M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g></g></g></svg></mjx-container>表示学习率。批量大小和学习率的值通常是手动预先指定，而不是通过模型训\t练得到的。 </p>\n<p>​\t  <strong>这些可以调整但不在训练过程中更新的参数称为超参数</strong>。</p>\n<p>​\t\t调参即为选择超参数的过程。超参数通常是我们根据训练迭代结果来调整的， 而训练迭代结果是在独立的验证数据集（validation dataset）上评估\t\t得到的。</p>\n<h4 id=\"从0实现线性回归代码\"><a href=\"#从0实现线性回归代码\" class=\"headerlink\" title=\"从0实现线性回归代码\"></a>从0实现线性回归代码</h4><div class=\"language-python\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">python</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #292D3E\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #676E95; font-style: italic\"># 从0开始实现线性回归代码</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">%</span><span style=\"color: #BABED8\">matplotlib inline</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">import</span><span style=\"color: #BABED8\"> random</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">import</span><span style=\"color: #BABED8\"> torch</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">from</span><span style=\"color: #BABED8\"> d2l </span><span style=\"color: #89DDFF; font-style: italic\">import</span><span style=\"color: #BABED8\"> torch </span><span style=\"color: #89DDFF; font-style: italic\">as</span><span style=\"color: #BABED8\"> d2l</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#生成数据集</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">synthetic_data</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #BABED8; font-style: italic\">w</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> </span><span style=\"color: #BABED8; font-style: italic\">b</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> </span><span style=\"color: #BABED8; font-style: italic\">num_examples</span><span style=\"color: #89DDFF\">):</span><span style=\"color: #BABED8\">  </span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">\"\"\"</span><span style=\"color: #676E95; font-style: italic\">生成y=Xw+b+噪声</span><span style=\"color: #89DDFF; font-style: italic\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    X </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">normal</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">num_examples</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> len</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">w</span><span style=\"color: #89DDFF\">)))</span><span style=\"color: #BABED8\">      </span><span style=\"color: #676E95; font-style: italic\"># 均值为0，方差为1，大小为：n个样本、w长度个特征</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    y </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">matmul</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">X</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> w</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> b                          </span><span style=\"color: #676E95; font-style: italic\"># matmul函数为不支持广播机制的矩阵乘法</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    y </span><span style=\"color: #89DDFF\">+=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">normal</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">0.01</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> y</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">shape</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\">                 </span><span style=\"color: #676E95; font-style: italic\"># 给y加一个随机噪声</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">return</span><span style=\"color: #BABED8\"> X</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> y</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">reshape</span><span style=\"color: #89DDFF\">((-</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">))</span><span style=\"color: #BABED8\">             </span><span style=\"color: #676E95; font-style: italic\">#将y作为列向量返回</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #BABED8\">true_w </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">2</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">-</span><span style=\"color: #F78C6C\">3.4</span><span style=\"color: #89DDFF\">])</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">true_b </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">4.2</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">features</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> labels </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">synthetic_data</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">true_w</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> true_b</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1000</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">print</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #89DDFF\">'</span><span style=\"color: #C3E88D\">features:</span><span style=\"color: #89DDFF\">'</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> features</span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">],</span><span style=\"color: #89DDFF\">'</span><span style=\"color: #BABED8\">\\n</span><span style=\"color: #C3E88D\">label:</span><span style=\"color: #89DDFF\">'</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> labels</span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">])</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">features</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">1.4632</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">0.5511</span><span style=\"color: #89DDFF\">])</span><span style=\"color: #BABED8\">     </span><span style=\"color: #676E95; font-style: italic\">#第一个样本的各特征值</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">label</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #F78C6C\">5.2498</span><span style=\"color: #89DDFF\">])</span><span style=\"color: #BABED8\">                </span><span style=\"color: #676E95; font-style: italic\">#第一个样本的标签</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\"># 绘制样本    </span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">d2l</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">set_figsize</span><span style=\"color: #89DDFF\">()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">d2l</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">plt</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">scatter</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">features</span><span style=\"color: #89DDFF\">[:,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">].</span><span style=\"color: #82AAFF\">detach</span><span style=\"color: #89DDFF\">().</span><span style=\"color: #82AAFF\">numpy</span><span style=\"color: #89DDFF\">(),</span><span style=\"color: #82AAFF\"> labels</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">detach</span><span style=\"color: #89DDFF\">().</span><span style=\"color: #82AAFF\">numpy</span><span style=\"color: #89DDFF\">(),</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\">;  </span><span style=\"color: #676E95; font-style: italic\">#绘制所有样本第一列特征与标签的散点图</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#读取数据集（用于实现小批量抽样）</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">data_iter</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #BABED8; font-style: italic\">batch_size</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> </span><span style=\"color: #BABED8; font-style: italic\">features</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> </span><span style=\"color: #BABED8; font-style: italic\">labels</span><span style=\"color: #89DDFF\">):</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    num_examples </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">len</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">features</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    indices </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">list</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">range</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">num_examples</span><span style=\"color: #89DDFF\">))</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    random</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">shuffle</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">indices</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\">     </span><span style=\"color: #676E95; font-style: italic\">#打乱indices中的数字顺序</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">for</span><span style=\"color: #BABED8\"> i </span><span style=\"color: #89DDFF; font-style: italic\">in</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">range</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> num_examples</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> batch_size</span><span style=\"color: #89DDFF\">):</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">        batch_indices </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">(</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">            indices</span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\">i</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #82AAFF\"> min</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">i </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #82AAFF\"> batch_size</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> num_examples</span><span style=\"color: #89DDFF\">)])</span><span style=\"color: #BABED8\">      </span><span style=\"color: #676E95; font-style: italic\">#每次取规模为batch_size的一些样本</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">        </span><span style=\"color: #89DDFF; font-style: italic\">yield</span><span style=\"color: #BABED8\"> features</span><span style=\"color: #89DDFF\">[</span><span style=\"color: #BABED8\">batch_indices</span><span style=\"color: #89DDFF\">],</span><span style=\"color: #BABED8\"> labels</span><span style=\"color: #89DDFF\">[</span><span style=\"color: #BABED8\">batch_indices</span><span style=\"color: #89DDFF\">]</span><span style=\"color: #BABED8\">     </span><span style=\"color: #676E95; font-style: italic\">#多次返回</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #BABED8\"> batch_size </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">10</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">for</span><span style=\"color: #BABED8\"> X</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> y </span><span style=\"color: #89DDFF; font-style: italic\">in</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">data_iter</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">batch_size</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> features</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> labels</span><span style=\"color: #89DDFF\">):</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #82AAFF\">print</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">X</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">'</span><span style=\"color: #BABED8\">\\n</span><span style=\"color: #89DDFF\">'</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> y</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">break</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">0.3934</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">2.5705</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">0.5849</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">-</span><span style=\"color: #F78C6C\">0.7124</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">0.1008</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">0.6947</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[-</span><span style=\"color: #F78C6C\">0.4493</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">-</span><span style=\"color: #F78C6C\">0.9037</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">2.3104</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">-</span><span style=\"color: #F78C6C\">0.2798</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[-</span><span style=\"color: #F78C6C\">0.0173</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">-</span><span style=\"color: #F78C6C\">0.2552</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">0.1963</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">-</span><span style=\"color: #F78C6C\">0.5445</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[-</span><span style=\"color: #F78C6C\">1.0580</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">-</span><span style=\"color: #F78C6C\">0.5180</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">0.8417</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #89DDFF\">-</span><span style=\"color: #F78C6C\">1.5547</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[-</span><span style=\"color: #F78C6C\">0.6316</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\">  </span><span style=\"color: #F78C6C\">0.9732</span><span style=\"color: #89DDFF\">]])</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">tensor</span><span style=\"color: #89DDFF\">([[-</span><span style=\"color: #F78C6C\">3.7623</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">7.7852</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">2.0443</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">6.3767</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">9.7776</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">5.0301</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">6.4541</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">3.8407</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[</span><span style=\"color: #F78C6C\">11.1396</span><span style=\"color: #89DDFF\">],</span></span>\n<span class=\"line\"><span style=\"color: #82AAFF\">        </span><span style=\"color: #89DDFF\">[-</span><span style=\"color: #F78C6C\">0.3836</span><span style=\"color: #89DDFF\">]])</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">w </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">normal</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">0.01</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #BABED8; font-style: italic\">size</span><span style=\"color: #89DDFF\">=(</span><span style=\"color: #F78C6C\">2</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">),</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #BABED8; font-style: italic\">requires_grad</span><span style=\"color: #89DDFF\">=True)</span><span style=\"color: #BABED8\">    </span><span style=\"color: #676E95; font-style: italic\">#均值为0，方差为0.01的2x1随机正态向量</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">b </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">zeros</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #BABED8; font-style: italic\">requires_grad</span><span style=\"color: #89DDFF\">=True)</span><span style=\"color: #BABED8\">             </span><span style=\"color: #676E95; font-style: italic\">#偏移量b初始化为0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#定义模型</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">linreg</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #BABED8; font-style: italic\">X</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> </span><span style=\"color: #BABED8; font-style: italic\">w</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> </span><span style=\"color: #BABED8; font-style: italic\">b</span><span style=\"color: #89DDFF\">):</span><span style=\"color: #BABED8\">  </span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">\"\"\"</span><span style=\"color: #676E95; font-style: italic\">线性回归模型</span><span style=\"color: #89DDFF; font-style: italic\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">return</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">matmul</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">X</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> w</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> b</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#定义损失函数</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">squared_loss</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #BABED8; font-style: italic\">y_hat</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> </span><span style=\"color: #BABED8; font-style: italic\">y</span><span style=\"color: #89DDFF\">):</span><span style=\"color: #BABED8\"> </span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">\"\"\"</span><span style=\"color: #676E95; font-style: italic\">均方损失</span><span style=\"color: #89DDFF; font-style: italic\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">return</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">(</span><span style=\"color: #BABED8\">y_hat </span><span style=\"color: #89DDFF\">-</span><span style=\"color: #BABED8\"> y</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">reshape</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">y_hat</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">shape</span><span style=\"color: #89DDFF\">))</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">**</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">2</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">/</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">2</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#定义优化算法</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">sgd</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #BABED8; font-style: italic\">params</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> </span><span style=\"color: #BABED8; font-style: italic\">lr</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> </span><span style=\"color: #BABED8; font-style: italic\">batch_size</span><span style=\"color: #89DDFF\">):</span><span style=\"color: #BABED8\"> </span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">\"\"\"</span><span style=\"color: #676E95; font-style: italic\">小批量随机梯度下降</span><span style=\"color: #89DDFF; font-style: italic\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">with</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">no_grad</span><span style=\"color: #89DDFF\">():</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">        </span><span style=\"color: #89DDFF; font-style: italic\">for</span><span style=\"color: #BABED8\"> param </span><span style=\"color: #89DDFF; font-style: italic\">in</span><span style=\"color: #BABED8\"> params</span><span style=\"color: #89DDFF\">:</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">            param </span><span style=\"color: #89DDFF\">-=</span><span style=\"color: #BABED8\"> lr </span><span style=\"color: #89DDFF\">*</span><span style=\"color: #BABED8\"> param</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">grad</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">/</span><span style=\"color: #BABED8\"> batch_size</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">            param</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #F07178\">grad</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">zero_</span><span style=\"color: #89DDFF\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">#训练</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">lr </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">0.03</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">num_epochs </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">3</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">net </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> linreg</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">loss </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> squared_loss</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">for</span><span style=\"color: #BABED8\"> epoch </span><span style=\"color: #89DDFF; font-style: italic\">in</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">range</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">num_epochs</span><span style=\"color: #89DDFF\">):</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">for</span><span style=\"color: #BABED8\"> X</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #BABED8\"> y </span><span style=\"color: #89DDFF; font-style: italic\">in</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">data_iter</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">batch_size</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> features</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> labels</span><span style=\"color: #89DDFF\">):</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">        l </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">loss</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">net</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">X</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> w</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> b</span><span style=\"color: #89DDFF\">),</span><span style=\"color: #82AAFF\"> y</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\">  </span><span style=\"color: #676E95; font-style: italic\"># X和y的小批量损失</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">        </span><span style=\"color: #676E95; font-style: italic\"># 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，才是标量。</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">        l</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">sum</span><span style=\"color: #89DDFF\">().</span><span style=\"color: #82AAFF\">backward</span><span style=\"color: #89DDFF\">()</span><span style=\"color: #BABED8\">  </span><span style=\"color: #676E95; font-style: italic\"># 计算关于[w,b]的梯度</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">        </span><span style=\"color: #82AAFF\">sgd</span><span style=\"color: #89DDFF\">([</span><span style=\"color: #82AAFF\">w</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> b</span><span style=\"color: #89DDFF\">],</span><span style=\"color: #82AAFF\"> lr</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> batch_size</span><span style=\"color: #89DDFF\">)</span><span style=\"color: #BABED8\">  </span><span style=\"color: #676E95; font-style: italic\"># 使用参数的梯度更新参数</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">    </span><span style=\"color: #89DDFF; font-style: italic\">with</span><span style=\"color: #BABED8\"> torch</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">no_grad</span><span style=\"color: #89DDFF\">():</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">        train_l </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">loss</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">net</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">features</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> w</span><span style=\"color: #89DDFF\">,</span><span style=\"color: #82AAFF\"> b</span><span style=\"color: #89DDFF\">),</span><span style=\"color: #82AAFF\"> labels</span><span style=\"color: #89DDFF\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">        </span><span style=\"color: #82AAFF\">print</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #C792EA\">f</span><span style=\"color: #C3E88D\">'epoch </span><span style=\"color: #F78C6C\">{</span><span style=\"color: #82AAFF\">epoch </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #82AAFF\"> </span><span style=\"color: #F78C6C\">1}</span><span style=\"color: #C3E88D\">, loss </span><span style=\"color: #F78C6C\">{</span><span style=\"color: #FFCB6B\">float</span><span style=\"color: #89DDFF\">(</span><span style=\"color: #82AAFF\">train_l</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #82AAFF\">mean</span><span style=\"color: #89DDFF\">())</span><span style=\"color: #C792EA\">:f</span><span style=\"color: #F78C6C\">}</span><span style=\"color: #C3E88D\">'</span><span style=\"color: #89DDFF\">)</span></span></code></pre></div><p>​\t\t</p>\n<p><strong>总结：线性回归恰好是一个在整个域中只有一个最小值的学习问题。 但是对像深度神经网络这样复杂的模型来说，损失平面上通常包含多个最小值。 深度学习实践者很少会去花费大力气寻找这样一组参数，使得在<em>训练集</em>上的损失达到最小。 事实上，更难做到的是找到一组参数，这组参数能够在我们从未见过的数据上实现较低的损失， 这一挑战被称为<em>泛化</em>（generalization）。</strong></p>\n","text":"Pytorch学习数据操作tensor为torch中的一个数据结构，可以参与运算，称为张量，即多个数值组成的数组，可能有多个维度 pythonimport to...","permalink":"/post/Pytorch学习","photos":[],"count_time":{"symbolsCount":"9.1k","symbolsTime":"8 mins."},"categories":[{"name":"深度学习","slug":"深度学习","count":1,"path":"api/categories/深度学习.json"}],"tags":[{"name":"Pytorch","slug":"Pytorch","count":1,"path":"api/tags/Pytorch.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Pytorch%E5%AD%A6%E4%B9%A0\"><span class=\"toc-text\">Pytorch学习</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C\"><span class=\"toc-text\">数据操作</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0\"><span class=\"toc-text\">线性代数</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%BE%AE%E7%A7%AF%E5%88%86\"><span class=\"toc-text\">微积分</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC\"><span class=\"toc-text\">自动求导</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\"><span class=\"toc-text\">线性神经网络</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92\"><span class=\"toc-text\">线性回归</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0\"><span class=\"toc-text\">损失函数</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D\"><span class=\"toc-text\">随机梯度下降</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E4%BB%8E0%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%BB%A3%E7%A0%81\"><span class=\"toc-text\">从0实现线性回归代码</span></a></li></ol></li></ol></li></ol></li></ol>","author":{"name":"Sonderlin","slug":"blog-author","avatar":"https://raw.githubusercontent.com/sonder-lin/Mypic/img/img/%E5%A4%B4%E5%83%8F.jpg","link":"/","description":"一位正在重塑知识的小蒟蒻~ <br /> <b><i>且视他人之疑目如盏盏鬼火，大胆地去走你的夜路。</i></b> <br /><br /> @ <b>qq：1425906813</b>","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"DOH隧道工具使用","uid":"977ed608adc923ebbb0d8daa2e5720c8","slug":"DOH隧道工具使用","date":"2024-07-07T06:05:49.000Z","updated":"2024-08-29T08:52:25.987Z","comments":true,"path":"api/articles/DOH隧道工具使用.json","keywords":null,"cover":null,"text":"dns2tcp使用教程https://www.jianshu.com/p/9e8367fee777 文件传输netcat工具安装https://blog.csd...","permalink":"/post/DOH隧道工具使用","photos":[],"count_time":{"symbolsCount":215,"symbolsTime":"1 mins."},"categories":[{"name":"DNS","slug":"DNS","count":1,"path":"api/categories/DNS.json"}],"tags":[{"name":"DoH隧道","slug":"DoH隧道","count":1,"path":"api/tags/DoH隧道.json"}],"author":{"name":"Sonderlin","slug":"blog-author","avatar":"https://raw.githubusercontent.com/sonder-lin/Mypic/img/img/%E5%A4%B4%E5%83%8F.jpg","link":"/","description":"一位正在重塑知识的小蒟蒻~ <br /> <b><i>且视他人之疑目如盏盏鬼火，大胆地去走你的夜路。</i></b> <br /><br /> @ <b>qq：1425906813</b>","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{}}