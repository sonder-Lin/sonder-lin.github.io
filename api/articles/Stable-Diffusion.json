{"title":"Stable Diffusion","uid":"9f952bd90e9edabc954e41df6aae978e","slug":"Stable-Diffusion","date":"2024-09-22T05:51:09.000Z","updated":"2024-09-22T10:29:32.526Z","comments":true,"path":"api/articles/Stable-Diffusion.json","keywords":null,"cover":[],"content":"<h1 id=\"Stable-Diffusion\"><a href=\"#Stable-Diffusion\" class=\"headerlink\" title=\"Stable Diffusion\"></a>Stable Diffusion</h1><p>Stable Diffusion 本身并不是一个模型，而是一个由多个模块和模型组成的系统架构，它由三大核心部件组成，每个组件都是一个神经网络系统，也称为三大基础模型：</p>\n<p><strong>1. CLIPText 用于文本编码，使文本数字化：</strong></p>\n<ul>\n<li>Input：输入文本（提示词 Prompt）；</li>\n<li>Output：77 token embeddings vectors，每个 token 向量有 768 个维度；</li>\n</ul>\n<p><strong>2. U-Net + Scheduler 用于逐步处理/扩散被转化到潜空间中的信息：</strong></p>\n<ul>\n<li>Input：文本嵌入和由噪点组成的起始多维矩阵（是一种结构化的数字列表，也称为张量 Tensor）；</li>\n<li>Output：处理后的信息矩阵；</li>\n</ul>\n<p><strong>3. AutoEncoder Decoder （主要是一个VAE：Variational AutoEncoder ）使用处理后的信息矩阵解码绘制出最终图像，把潜空间的运算结果解码成实际图片维度：</strong></p>\n<ul>\n<li>Input：处理后的信息矩阵，维度：4, 64, 64；</li>\n<li>Output：生成的图像，维度：3, 512, 512 即 RGB三个通道、和两维像素尺寸。</li>\n</ul>\n<h1 id=\"CLIP\"><a href=\"#CLIP\" class=\"headerlink\" title=\"CLIP\"></a>CLIP</h1><h1 id=\"注意力机制\"><a href=\"#注意力机制\" class=\"headerlink\" title=\"注意力机制\"></a>注意力机制</h1><p><img src=\"https://raw.githubusercontent.com/sonder-Lin/Mypic/img/img/image-20240922172945700.png\" alt=\"image-20240922172945700\"></p>\n","feature":true,"text":"Stable DiffusionStable Diffusion 本身并不是一个模型，而是一个由多个模块和模型组成的系统架构，它由三大核心部件组成，每个组件都是...","permalink":"/post/Stable-Diffusion","photos":[],"count_time":{"symbolsCount":509,"symbolsTime":"1 mins."},"categories":[{"name":"深度学习","slug":"深度学习","count":4,"path":"api/categories/深度学习.json"}],"tags":[{"name":"AIGC","slug":"AIGC","count":2,"path":"api/tags/AIGC.json"},{"name":"SD扩散模型","slug":"SD扩散模型","count":1,"path":"api/tags/SD扩散模型.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Stable-Diffusion\"><span class=\"toc-text\">Stable Diffusion</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#CLIP\"><span class=\"toc-text\">CLIP</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6\"><span class=\"toc-text\">注意力机制</span></a></li></ol>","author":{"name":"Sonderlin","slug":"blog-author","avatar":"https://raw.githubusercontent.com/sonder-lin/Mypic/img/img/%E5%A4%B4%E5%83%8F.jpg","link":"/","description":"一位正在重塑知识的小蒟蒻~ <br /> <b><i>且视他人之疑目如盏盏鬼火，大胆地去走你的夜路。</i></b> <br /><br /> @ <b>qq：1425906813</b>","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{},"next_post":{"title":"注意力机制","uid":"355624fb0490d5f1612ed79605ab0b34","slug":"attention","date":"2024-09-22T05:51:09.000Z","updated":"2024-09-22T12:55:12.290Z","comments":true,"path":"api/articles/attention.json","keywords":null,"cover":[],"text":"Attention自注意力机制Self-attention注意力机制在设计之初的目标是接收一段文本，预测其下一个词。 首先，输入文本会被切分成小块，称之为tok...","permalink":"/post/attention","photos":[],"count_time":{"symbolsCount":"2k","symbolsTime":"2 mins."},"categories":[{"name":"深度学习","slug":"深度学习","count":4,"path":"api/categories/深度学习.json"}],"tags":[{"name":"attention","slug":"attention","count":1,"path":"api/tags/attention.json"},{"name":"transformer","slug":"transformer","count":1,"path":"api/tags/transformer.json"}],"author":{"name":"Sonderlin","slug":"blog-author","avatar":"https://raw.githubusercontent.com/sonder-lin/Mypic/img/img/%E5%A4%B4%E5%83%8F.jpg","link":"/","description":"一位正在重塑知识的小蒟蒻~ <br /> <b><i>且视他人之疑目如盏盏鬼火，大胆地去走你的夜路。</i></b> <br /><br /> @ <b>qq：1425906813</b>","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}