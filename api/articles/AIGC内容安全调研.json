{"title":"AIGC内容安全调研","uid":"71f02e50762204cb69b459e8f982ddf3","slug":"AIGC内容安全调研","date":"2024-09-20T05:51:09.000Z","updated":"2024-09-26T09:45:40.537Z","comments":true,"path":"api/articles/AIGC内容安全调研.json","keywords":null,"cover":null,"content":"<h1 id=\"调研\"><a href=\"#调研\" class=\"headerlink\" title=\"调研\"></a>调研</h1><h4 id=\"2024ECCV——To-Generate-or-Not-Safety-Driven-Unlearned-Diffusion-Models-Are-Still-Easy-to-Generate-Unsafe-Images-…-For-Now\"><a href=\"#2024ECCV——To-Generate-or-Not-Safety-Driven-Unlearned-Diffusion-Models-Are-Still-Easy-to-Generate-Unsafe-Images-…-For-Now\" class=\"headerlink\" title=\"2024ECCV——To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy to Generate Unsafe Images … For Now\"></a>2024ECCV——To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy to Generate Unsafe Images … For Now</h4><p>问题：本文针对扩散模型生成图像的有害内容安全问题，对现有的有害概念非学习（不通过重新训练或微调模型来移除模型生成不适当内容的方式）策略的有效性存疑，因此提出一种对抗性提示攻击算法UnlearnDiffatk来评估扩散模型在经过有害概念非学习后是否还会产生有害内容，来评估非学习策略的有效性，并与其他的对抗性提示攻击算法进行对比，展示UnlearnDiffatk的有效性和效率。</p>\n<h4 id=\"2024ECCV——Reliable-and-Efficient-Concept-Erasure-of-Text-to-Image-Diffusion-Models\"><a href=\"#2024ECCV——Reliable-and-Efficient-Concept-Erasure-of-Text-to-Image-Diffusion-Models\" class=\"headerlink\" title=\"2024ECCV——Reliable and Efficient Concept Erasure of Text-to-Image Diffusion Models\"></a>2024ECCV——Reliable and Efficient Concept Erasure of Text-to-Image Diffusion Models</h4><p>问题：本文同样是针对扩散模型生成图像的有害内容安全问题，针对已提出的几种在扩散模型中擦除不恰当概念（遗忘）的方法往往存在擦除不彻底、计算资源消耗过多、损害正常内容的生成能力等问题，提出了一种可靠高效的擦除方法（RECE），相较其他方法效率更高、擦除更彻底、对正常内容的生成能力的负面影响更小。</p>\n<h4 id=\"2024ICLR——To-Generate-or-Not-Safety-Driven-Unlearned-Diffusion-Models-Are-Still-Easy-to-Generate-Unsafe-Images-…-For-Now\"><a href=\"#2024ICLR——To-Generate-or-Not-Safety-Driven-Unlearned-Diffusion-Models-Are-Still-Easy-to-Generate-Unsafe-Images-…-For-Now\" class=\"headerlink\" title=\"2024ICLR——To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy to Generate Unsafe Images … For Now\"></a>2024ICLR——To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy to Generate Unsafe Images … For Now</h4><p><strong>（这篇作者相当于否认了所有模型训练后的概念移除方法）</strong></p>\n<p>问题：针对扩散模型生成图像的有害内容安全问题，现有的解决方法主要分为两种：</p>\n<p>1.<strong>数据集预筛选（非学习）</strong>：在训练模型之前，通过剔除含有不适宜内容的数据，减少模型学到这些概念的可能性。</p>\n<p>2.<strong>训练后概念移除</strong>：通过训练或调整已经训练好的模型，删除模型中的特定概念。这些方法通常比重新训练整个模型更具可行性，并且许多模型的“清理”版本也被公开发布。</p>\n<p>作者发现了现有方法的局限性：</p>\n<p>1.即使在数据预处理中使用过滤器（例如NSFW过滤器），也无法完全避免模型学到不适当内容，存在较多“假阴性”（漏网之鱼）；</p>\n<p>2.尽管一些方法（如Erased Stable Diffusion, Unified Concept Editing）通过调整模型的权重永久删除了某些敏感概念，但在实验中作者认为这些方法并不牢固，并可能会被绕过。</p>\n<p>因此，作者基于其核心假设：这些概念移除方法实际上是通过某种形式的<strong>输入过滤</strong>（而非完全删除概念）来实现的。因此，概念仍然存在于模型中，只是被映射到了不同的词嵌入上，这使得这些方法易于被复杂的输入提示绕过，因此作者设计了一种攻击方法，旨在通过调整输入提示词来重新激活模型中隐藏的、被移除的概念，通过学习特定的输入词嵌入，重新激活那些“被删除”的敏感内容。</p>\n<p>方法目标：在没有修改模型权重的前提下，设计一个特殊的输入提示（或嵌入），从模型中生成原本已经被“移除”的概念（如名人形象、特定艺术风格、NSFW内容等）</p>\n<h4 id=\"2024NAACL——Universal-Prompt-Optimizer-for-Safe-Text-to-Image-Generation\"><a href=\"#2024NAACL——Universal-Prompt-Optimizer-for-Safe-Text-to-Image-Generation\" class=\"headerlink\" title=\"2024NAACL——Universal Prompt Optimizer for Safe Text-to-Image Generation\"></a>2024NAACL——Universal Prompt Optimizer for Safe Text-to-Image Generation</h4><p>本文作者针对扩散模型生成图像的有害内容安全问题，针对现有解决方案在实际应用中存在很多限制（影响用户体验、<strong>需要已知模型内部结构</strong>、缺乏实用性），提出了首个黑盒提示词优化器POSI，能够自动将不安全的文本提示转换为安全的提示，同时保持文本语义基本不变，实用性较强，能够在不需要访问T2I模型内部结构的情况下生成安全图像。POSI的核心思想是通过提示词优化，修改输入的有害提示词，使得生成的图像既安全又语义保持一致。</p>\n<h4 id=\"2024ICLR——RING-A-BELL-HOW-RELIABLE-ARE-CONCEPT-REMOVAL-METHODS-FOR-DIFFUSION-MODELS\"><a href=\"#2024ICLR——RING-A-BELL-HOW-RELIABLE-ARE-CONCEPT-REMOVAL-METHODS-FOR-DIFFUSION-MODELS\" class=\"headerlink\" title=\"2024ICLR——RING-A-BELL! HOW RELIABLE ARE CONCEPT REMOVAL METHODS FOR DIFFUSION MODELS?\"></a>2024ICLR——RING-A-BELL! HOW RELIABLE ARE CONCEPT REMOVAL METHODS FOR DIFFUSION MODELS?</h4><p>针对当前文本到图像扩散模型（如Stable Diffusion）中的概念移除方法的可靠性尚未得到全面检验这一问题，作者提出了</p>\n<p>Ring-A-Bell，一种新颖的模型无关红队工具，用于评估扩散模型的安全机制。该工具不需要预先了解目标模型的结构，可以通过概念提取获取敏感和不当概念的全局表示，并基于这些表示自动生成问题提示词，以揭示模型生成不当内容的风险。</p>\n<h4 id=\"2024【貌似是首个研究视频内容安全的】arXiv——Towards-Understanding-Unsafe-Video-Generation\"><a href=\"#2024【貌似是首个研究视频内容安全的】arXiv——Towards-Understanding-Unsafe-Video-Generation\" class=\"headerlink\" title=\"2024【貌似是首个研究视频内容安全的】arXiv——Towards Understanding Unsafe Video Generation\"></a>2024【貌似是首个研究视频内容安全的】arXiv——Towards Understanding Unsafe Video Generation</h4><p>作者通过实验验证了现有的视频生成模型可以生成不安全内容。首先，他们从4chan和Lexica等网站上收集了大量可能生成不安全内容的提示词（prompts）。这些提示词曾用于生成不安全的图像，因此作者假设它们也可能引发视频生成模型产生不安全视频。</p>\n<p>他们使用三个最先进的开源视频生成模型（SOTA VGMs）来生成不安全视频，并从最初的5607个视频中挑选出2112个视频进行进一步分析。为了定义不安全视频的类型，作者通过聚类分析（k-means）和主题编码分析（thematic coding analysis）对生成的视频进行分类，最终确定了五类不安全视频：扭曲/怪异、恐怖、色情、暴力/血腥、以及政治类。</p>\n<p><strong>并通过在线用户调研人工标记，从2112个视频中识别出937个被一致认为是不安全的视频，形成了首个不安全视频生成数据集。</strong></p>\n<p>在实验生成数据集的基础上，作者进一步研究如何防止生成不安全的视频。他们提出了一种新的方法，称为<strong>潜变量防御（Latent Variable Defense, LVD）</strong>，该方法在模型的内部采样过程中工作，可以提前终止生成不安全视频，减少计算资源的消耗。</p>\n","text":"调研2024ECCV——To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Sti...","permalink":"/post/AIGC内容安全调研","photos":[],"count_time":{"symbolsCount":"2.4k","symbolsTime":"2 mins."},"categories":[{"name":"AI安全","slug":"AI安全","count":8,"path":"api/categories/AI安全.json"}],"tags":[{"name":"AIGC安全","slug":"AIGC安全","count":3,"path":"api/tags/AIGC安全.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E8%B0%83%E7%A0%94\"><span class=\"toc-text\">调研</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#2024ECCV%E2%80%94%E2%80%94To-Generate-or-Not-Safety-Driven-Unlearned-Diffusion-Models-Are-Still-Easy-to-Generate-Unsafe-Images-%E2%80%A6-For-Now\"><span class=\"toc-text\">2024ECCV——To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy to Generate Unsafe Images … For Now</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#2024ECCV%E2%80%94%E2%80%94Reliable-and-Efficient-Concept-Erasure-of-Text-to-Image-Diffusion-Models\"><span class=\"toc-text\">2024ECCV——Reliable and Efficient Concept Erasure of Text-to-Image Diffusion Models</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#2024ICLR%E2%80%94%E2%80%94To-Generate-or-Not-Safety-Driven-Unlearned-Diffusion-Models-Are-Still-Easy-to-Generate-Unsafe-Images-%E2%80%A6-For-Now\"><span class=\"toc-text\">2024ICLR——To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy to Generate Unsafe Images … For Now</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#2024NAACL%E2%80%94%E2%80%94Universal-Prompt-Optimizer-for-Safe-Text-to-Image-Generation\"><span class=\"toc-text\">2024NAACL——Universal Prompt Optimizer for Safe Text-to-Image Generation</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#2024ICLR%E2%80%94%E2%80%94RING-A-BELL-HOW-RELIABLE-ARE-CONCEPT-REMOVAL-METHODS-FOR-DIFFUSION-MODELS\"><span class=\"toc-text\">2024ICLR——RING-A-BELL! HOW RELIABLE ARE CONCEPT REMOVAL METHODS FOR DIFFUSION MODELS?</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#2024%E3%80%90%E8%B2%8C%E4%BC%BC%E6%98%AF%E9%A6%96%E4%B8%AA%E7%A0%94%E7%A9%B6%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%E7%9A%84%E3%80%91arXiv%E2%80%94%E2%80%94Towards-Understanding-Unsafe-Video-Generation\"><span class=\"toc-text\">2024【貌似是首个研究视频内容安全的】arXiv——Towards Understanding Unsafe Video Generation</span></a></li></ol></li></ol></li></ol></li></ol>","author":{"name":"Sonderlin","slug":"blog-author","avatar":"https://raw.githubusercontent.com/sonder-lin/Mypic/img/img/%E5%A4%B4%E5%83%8F.jpg","link":"/","description":"一位正在重塑知识的小蒟蒻~ <br /> <b><i>且视他人之疑目如盏盏鬼火，大胆地去走你的夜路。</i></b> <br /><br /> @ <b>qq：1425906813</b>","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"Diffusion Model","uid":"7ce7aaea6148fcaf3be1f2eb31902870","slug":"diffusion model","date":"2024-09-21T05:51:09.000Z","updated":"2024-09-22T13:03:21.304Z","comments":true,"path":"api/articles/diffusion model.json","keywords":null,"cover":[],"text":"Diffusion Model原理解析前向扩散过程前向扩散过程本质上为一个对原始图片输入逐步加噪的过程，公式如下所示：其中，表示在时刻的噪音，其服从正态分布：....","permalink":"/post/diffusion model","photos":[],"count_time":{"symbolsCount":632,"symbolsTime":"1 mins."},"categories":[{"name":"深度学习","slug":"深度学习","count":4,"path":"api/categories/深度学习.json"}],"tags":[{"name":"AIGC","slug":"AIGC","count":2,"path":"api/tags/AIGC.json"},{"name":"扩散模型","slug":"扩散模型","count":1,"path":"api/tags/扩散模型.json"}],"author":{"name":"Sonderlin","slug":"blog-author","avatar":"https://raw.githubusercontent.com/sonder-lin/Mypic/img/img/%E5%A4%B4%E5%83%8F.jpg","link":"/","description":"一位正在重塑知识的小蒟蒻~ <br /> <b><i>且视他人之疑目如盏盏鬼火，大胆地去走你的夜路。</i></b> <br /><br /> @ <b>qq：1425906813</b>","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"Towards Understanding Unsafe Video Generation","uid":"8efbfa0326f4c642fe60c9dd565aaa12","slug":"Towards Understanding Unsafe Video Generation","date":"2024-09-20T05:51:09.000Z","updated":"2024-09-23T12:06:12.866Z","comments":true,"path":"api/articles/Towards Understanding Unsafe Video Generation.json","keywords":null,"cover":[],"text":"aigc视频安全：Towards Understanding Unsafe Video Generation论文摘要视频生成模型（VGMs）近年来展示了生成高质...","permalink":"/post/Towards Understanding Unsafe Video Generation","photos":[],"count_time":{"symbolsCount":"2.1k","symbolsTime":"2 mins."},"categories":[{"name":"AI安全","slug":"AI安全","count":8,"path":"api/categories/AI安全.json"}],"tags":[{"name":"AIGC安全","slug":"AIGC安全","count":3,"path":"api/tags/AIGC安全.json"}],"author":{"name":"Sonderlin","slug":"blog-author","avatar":"https://raw.githubusercontent.com/sonder-lin/Mypic/img/img/%E5%A4%B4%E5%83%8F.jpg","link":"/","description":"一位正在重塑知识的小蒟蒻~ <br /> <b><i>且视他人之疑目如盏盏鬼火，大胆地去走你的夜路。</i></b> <br /><br /> @ <b>qq：1425906813</b>","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}