[{"id":"e2ee55e7f1ab0560149a7f081543d28e","title":"经典机器学习模型","content":"经典机器学习模型","slug":"经典机器学习模型","date":"2024-11-08T02:07:06.000Z","categories_index":"机器学习","tags_index":"机器学习,经典模型","author_index":"Sonderlin"},{"id":"831153dd197dfce444bc258223799115","title":"集成学习","content":"集成学习框架参考：https://mp.weixin.qq.com/s?__biz=MzU0MDQ1NjAzNg==&amp;mid=2247566920&amp;idx=3&amp;sn=48bb344c64437c2acb8a66c9c8a8f273&amp;chksm=fb3b6343cc4cea552ddedda4bd639130eaf56eb508b7975230febcb779ed58dd80c71f1c1275&amp;scene=27\n\nBagging\nBagging 全称叫 Bootstrap aggregating，即每个基学习器都会对训练集进行有放回抽样得到子训练集，每个基学习器基于不同子训练集进行训练，最后综合所有基学习器的预测值得到最终的预测结果。\nBagging常用的综合方法是投票法，票数最多的类别为预测类别。\n\n\nBoosting\nBoosting训练过程为阶梯状，基模型的训练是有顺序的，每个基模型都会在前一个基模型学习的基础上进行学习，最终综合所有基模型的预测值产生最终的预测结果，用的比较多的综合方式为加权法。\n\n\nStacking\nStacking 是先用全部数据训练好基模型，然后每个基模型都对每个训练样本进行的预测，其预测值将作为训练样本的特征值，最终会得到新的训练样本，然后基于新的训练样本进行训练得到模型，然后得到最终预测结果。\n\n\n","slug":"集成学习","date":"2024-11-06T05:38:58.000Z","categories_index":"集成学习","tags_index":"集成学习","author_index":"Sonderlin"},{"id":"f708a9779c264010c95b53120252c787","title":"Solidity","content":"智能合约开发第一个Solidity程序pragma solidity ^0.8.21;contract HelloWeb3{    string public s &#x3D; “Hello Web3!”;}\npragma solidity ^0.8.21;  源文件所使用的 Solidity 版本只允许大于或等于 0.8.21 （^ 表大于或等于）第2行代码为创建HelloWeb3合约，并初始化其中的s字符串变量常用的在线编辑器Remix：https://remix.ethereum.org\n变量solidity中变量声明格式为：类型+属性+变量名\n","slug":"solidity","date":"2024-11-05T07:23:21.000Z","categories_index":"智能合约","tags_index":"solidity语法,智能合约开发","author_index":"Sonderlin"},{"id":"f953a678ee781dfc0167a1b2b1c56f02","title":"算法笔记","content":"排序快速排序（nlogn）分治思想算法框架：1.确定分界点（随便取）\n2.调整区间\n\n\n3.递归处理左右两段\n思想模拟\n\n红色i保证左侧全部小于等于x，绿色j保证右侧大于等于x\n当中间部分不符合时各自停下进行swap\n算法模板cvoid quick_sort(int q[], int l, int r)\n&#123;\n    //递归的终止情况\n    if (l &gt;= r) return;\n    //第一步：划分子问题\n    int i = l - 1, j = r+1, x = q[l+r &gt;&gt; 1];\n    while (i &lt; j)\n    &#123;\n        do i++; while (q[i] &lt; x);\n        do j -- ; while (q[j] &gt; x);\n        if (i &lt; j) swap(q[i], q[j]);\n    &#125;\n    //第二步：递归处理子问题\n    quick_sort(q, l, j), quick_sort(q, j+1, r);\n&#125;\nint main()&#123;\n    quick_sort(q,0,n-1);\n&#125;归并排序（nlogn）分治思想算法框架：1.确定分界点Mid：取中间，将区间划分为两段\n2.递归排序左右两段子序列\n3.将左右两段合二为一（双指针算法）\n思想模拟两个指针分别逐一比较两个子序列中的各元素，且当两者相等时，优先左侧序列进入（从而使得归并排序为稳定的排序算法）\n快排也可修改为稳定的排序：将元素修改为一个pair&lt;元素值、下标&gt;算法模板cvoid merge_sort(int q[], int l, int r)\n&#123;\n    //递归的终止情况\n    if (l &gt;= r) return;\n    //第二步：递归处理左右两段\n    int mid = l+r &gt;&gt; 1;\n    merge_sort(q, l, mid);\n    merge_sort(q, mid+1, r);\n    //第三步：合并左右两段子序列\n    int k = 0, i = l, j = mid+1;\n    while (i &lt;= mid &amp;&amp; j &lt;= r)\n        if (q[i] &lt;= q[j]) tmp[k++] = q[i++];\n        else tmp[k++] = q[j++];\n    while (i &lt;= mid) tmp[k++] = q[i++];\n    while (j &lt;= r) tmp[k++] = q[j++];\n    for (i = l, j = 0; i &lt;= r; i++, j++) q[i] = tmp[j];\n&#125;二分本质：每次将区间长度减半，同时保证答案一定落在区间中，最后当区间长度为1时，即为答案；\n此外，二分一定有解，最后可根据答案判断题意是否有解\n整数二分\n\n二分本质即：根据某种性质（check函数），将区间一分为二，然后不断迭代，可以找到区间分割处的两个边界点\n以下板子则分别对应找到两个区间的两个分界点，灵活运用即可\n板子记忆：\n当r&#x3D;mid时，mid&#x3D;(l+r)&#x2F;2;\n当l&#x3D;mid时，mid&#x3D;(l+r+1)&#x2F;2;（只所以加1，是为了避免陷入[r-1,r]的死循环）\n板子如下：cbool check(int x) &#123;/* ... */&#125; // 检查x是否满足某种性质\n\n// 区间[l, r]被划分成[l, mid]和[mid+1, r]时使用：\nint bsearch_1(int l, int r)\n&#123;\n    while (l &lt; r)\n    &#123;\n        int mid = l+r &gt;&gt; 1;\n        if (check(mid)) r = mid;    // check()判断mid是否满足性质\n        else l = mid+1;\n    &#125;\n    return l;\n&#125;\n// 区间[l, r]被划分成[l, mid - 1]和[mid, r]时使用：\nint bsearch_2(int l, int r)\n&#123;\n    while (l &lt; r)\n    &#123;\n        int mid = l+r+1 &gt;&gt; 1;\n        if (check(mid)) l = mid;\n        else r = mid - 1;\n    &#125;\n    return l;\n&#125;浮点数二分跟整数二分类似，但更简单，具体体现为：\n\n不需要特殊处理边界情况\n因为浮点数二分时，区间长度一般为浮点数，所以当区间长度很小时，就可近似认为长度已经为0，此时仍落在区间中的值，即为答案\n\n算法模板cwhile(r-l&gt;1e-8)&#123;\n        double mid=(l+r)/2;\n        if(mid*mid*mid&gt;n)&#123;\n            r=mid;\n        &#125;else&#123;\n            l=mid;\n        &#125;\n&#125;\n\n//或者无脑迭代多次（此处一百次），即将区间长度除以2^100\nfor(int i=0;i&lt;100;i++)&#123;\n        double mid=(l+r)/2;\n        if(mid*mid*mid&gt;n)&#123;\n            r=mid;\n        &#125;else&#123;\n            l=mid;\n        &#125;\n&#125;","slug":"算法笔记","date":"2024-11-04T04:34:39.000Z","categories_index":"算法学习","tags_index":"算法,C++","author_index":"Sonderlin"},{"id":"d3ee7ff5b0caab720c6799b8d71b17d7","title":"可投期刊/会议汇总","content":"期刊 IEEE Transactions on Network and Service Management\nCCF C类期刊\n中科院2区\n审稿速度：好像有点慢？\n较易\n\n相关论文\nR. Mitsuhashi, Y. Jin, K. Iida, T. Shinagawa and Y. Takai, “Malicious DNS Tunnel Tool Recognition Using Persistent DoH Traffic Analysis”\n\nIEEE Transactions on Information Forensics and Security\nCCF A类期刊\n中科院1区\n较难\n\n相关论文\nT. Zebin, S. Rezvy and Y. Luo, “An Explainable AI-Based Intrusion Detection System for DNS Over HTTPS (DoH) Attacks”\n\nJournal of Information Security and Applications\nCCF C类期刊\n中科院2&#x2F;3区\n较易\n\n相关论文\nS. Wu, W. Wang, Z. Ding, Detecting malicious DoH traffic: Leveraging small sample analysis and adversarial networks for detection\nZ. Zeng, P. Xun, W. Peng, B. Zhao, Toward identifying malicious encrypted traffic with a causality detection system\n\nComputer Network\nCCF B类期刊\n中科院2&#x2F;3区\n\n相关论文\nM. Zhan, Y. Li, G. Yu, B. Li, W. Wang, Detecting dns over https based data exfiltration\n\n\n会议ARES ‘20: Proceedings of the 15th International Conference on Availability, Reliability and Security","slug":"可投期刊会议汇总","date":"2024-10-31T03:04:24.000Z","categories_index":"机器学习","tags_index":"论文投稿","author_index":"Sonderlin"},{"id":"659a6798e9eafcc50623a9ff58b39c34","title":"跑项目常见问题记录","content":"python导包时总是显示不存在，但明明存在对应包通过设置环境变量 PYTHONPATH 来确保 Python 能找到所需的模块：\nbashexport PYTHONPATH=$PYTHONPATH:/path/to/your/module_directoryssh端口映射，访问服务器jupyterssh -L 1234:localhost:5678 [用户名@]远程主机\n这将会把你对localhost:1234的请求通过SSH隧道转发到远程主机的localhost:5678端口。\n并请确保远程主机上的5678端口有服务在运行，否则无法访问。\n","slug":"跑项目常见问题记录","date":"2024-10-04T08:28:09.000Z","categories_index":"python","tags_index":"问题记录","author_index":"Sonderlin"},{"id":"9f952bd90e9edabc954e41df6aae978e","title":"Stable Diffusion","content":"Stable DiffusionStable Diffusion 本身并不是一个模型，而是一个由多个模块和模型组成的系统架构，它由三大核心部件组成，每个组件都是一个神经网络系统，也称为三大基础模型：\n1. CLIPText 用于文本编码，使文本数字化：\n\nInput：输入文本（提示词 Prompt）；\nOutput：77 token embeddings vectors，每个 token 向量有 768 个维度；\n\n2. U-Net + Scheduler 用于逐步处理/扩散被转化到潜空间中的信息：\n\nInput：文本嵌入和由噪点组成的起始多维矩阵（是一种结构化的数字列表，也称为张量 Tensor）；\nOutput：处理后的信息矩阵；\n\n3. AutoEncoder Decoder （主要是一个VAE：Variational AutoEncoder ）使用处理后的信息矩阵解码绘制出最终图像，把潜空间的运算结果解码成实际图片维度：\n\nInput：处理后的信息矩阵，维度：4, 64, 64；\nOutput：生成的图像，维度：3, 512, 512 即 RGB三个通道、和两维像素尺寸。\n\nCLIP注意力机制","slug":"Stable-Diffusion","date":"2024-09-22T05:51:09.000Z","categories_index":"深度学习","tags_index":"SD扩散模型,AIGC","author_index":"Sonderlin"},{"id":"355624fb0490d5f1612ed79605ab0b34","title":"注意力机制","content":"Attention自注意力机制Self-attention注意力机制在设计之初的目标是接收一段文本，预测其下一个词。\n\n\n首先，输入文本会被切分成小块，称之为token（可能由单个单词或者多个单词组成），即一个句子的一个小单位\n\n\n接着，在transformer模型中，我们将之前划分的每一个token关联到一个称为嵌入向量（embedding）的高维向量中，而在高维空间中向量的方向即可表示对应的语义信息。\n\n\n而transformer模型的目标即是 在将一个文本句子编码成一个个单个词后，通过逐步调整对应词的嵌入向量（embeddings） 来融入对应词的上下文信息（语义信息）。\n\n\n\n\n而如何逐步调整文本句子中每一个词对应的嵌入向量（embeddings）以融入语义信息则是transformer模型的核心——注意力机制。\n对于理解这个问题，可以以一个这样的例子进行理解：假设现在一个句子中的语义信息只存在于形容词对名词的作用。\na fluffy blue creature roamed the verdant forest\n因此，可以想象成每个名词，此处以creature为例，向前面的词发出询问：我的前面有形容词吗？显然，fluffy和blue这两个词想回应：是的，我是你前面的形容词。\n上述的提问在注意力机制中被编码为一个向量，称为对应词的query向量，而要计算这个query向量则需要先取一个矩阵，即为，与对应词embedding进行矩阵相乘得到对应词的query向量。\n其中，被称为查询矩阵，其中的元素为模型需要去学习的参数，形状为128x12288（相当于将embedding降维至128维了）。\n\n\n此外，在对提问定义后，那上述所谓“形容词的回答”该如何定义呢？因此我们引入了第二个待学习参数矩阵——键矩阵，同样与embedding相乘得到键向量,与查询矩阵相同，键矩阵同样将embedding降维至128维的低维空间。\n当查询query向量与键key向量的方向接近时，我们就能认为它们相匹配，即可将其当作对查询query的积极回应，从而我们通过计算每个词对应query、key向量的点积，根据点积的大小即可，判断query与key的匹配程度。\n\n\n而这些匹配程度对应值的大小，我们后续将用来作为权重，因此需要介于0-1，因此，我们对于每一列应用softmax函数进行归一化，从而得到权重：\n\n\n\n\n在训练transformer模型时，我们可以通过将文本信息根据token拆分成多个子集，并行地在模型上对其进行训练\n\n\n但为了保障这种并行性，意味着不能让后面词的存在影响前面句子的预测，不然会泄露，因此在训练时需要保证模型只能已知前面的词，也就是权重左下角在softmax层运算前全设为负无穷，得到的最终softmax输出权重即为0。这种机制即掩码（masking）机制。\n\n\n\n\n接着，我们回到如何调整embedding能嵌入语义信息这一问题，为了实现这一目标，我们将用到第三个矩阵：值矩阵，将其乘以前面词的embedding，即可得到前面一个词对当前词的值向量Value，即要给当前词的embedding要加上的向量，从而实现对当前词embedding的调整，即融入前一个词对其的语义影响。\n显然，这个值向量与词embedding处于同一维度，因此的形状为12288x12288\n因此，我们计算任意两个词之间的value，使用之前的权重进行加权求和，得到对应embe-dding需要加上的量（调整方向，融入语义信息）\n\n\n\n\n以上即为单头自注意力机制的原理，其由三个待学习的参数矩阵构成：、、\n\n\n此外，为了保证并行性和运算速度，通常将V矩阵进行分解：\n\n\n交叉注意力机制Cross-attention交叉注意力机制与自注意力机制基本相同，唯一的区别在于：和矩阵作用于不同的数据集：\n\n\n例如在机器翻译中，查询来自一种语言，键可能来自另一种语言，即可描述为一种语言中的词对应于其他语言中的哪些词，因此可以发现一个句子中后面的词对前面词的翻译预测不会有影响，因此不再使用掩码机制（masking）\n多头注意力机制Multi-headed attention\n\n即多头，进一步提高并行性，在最后将各头给出的embedding变化量加起来，给原始embedding加上这个和，即可得到一个更精确的调整后的embedding。\n\n\n\n\n\n\n参考视频：https://www.bilibili.com/video/BV1TZ421j7Ke/?spm_id_from=333.337.search-card.all.click&amp;vd_source=2fc3d89c840e069d13993f1514edd1d8\n（3b1b无敌！）\n","slug":"attention","date":"2024-09-22T05:51:09.000Z","categories_index":"深度学习","tags_index":"attention,transformer","author_index":"Sonderlin"},{"id":"7ce7aaea6148fcaf3be1f2eb31902870","title":"Diffusion Model","content":"Diffusion Model原理解析前向扩散过程前向扩散过程本质上为一个对原始图片输入逐步加噪的过程，公式如下所示：其中，表示在时刻的噪音，其服从正态分布：.\n从开始使用上述公式进行迭代的推导，经过化简可以发现，由可以直接求出任意时刻，从而极大提升加噪过程的速度：\n反向去噪过程对于反向去噪过程，目标是求出，而目前只是已知，即为。显然，去噪无法一步到位，退而求其次，即先求出，而在前向扩散过程中已知。\n\n\n因此，在此处利用贝叶斯公式，即可求出：\n\n其中，已知，与未知。\n由前向扩散过程可知，若已知时，可直接求出任意时刻的，但在反向去噪过程中，为目标输出，显然未知。\n因此，利用前向加噪过程中的公式进行替换：\n\n因此，将所有项代入贝叶斯公式，化简可得到的一个正态分布，其方差固定，均值为：$$\\mu_\\theta(x_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{1 - \\bar{\\alpha}t}{\\sqrt{1 - \\alpha_t}} z_\\theta(x_t, t) \\right)$$其中，噪音成为了唯一的未知。因此，只需要知道每个到$x{t-1}过程中加入的噪声z_t，就可以得到求出x_{t-1}，不断迭代，最后即可完成去噪，求出x_0$。\n那噪音如何得到呢？利用前向扩散过程中的噪音与x作为训练集训练机器学习模型，最后在去噪时对噪音进行预测即可得到，这即是扩散模型的核心（预测噪音）。\n","slug":"diffusion model","date":"2024-09-21T05:51:09.000Z","categories_index":"深度学习","tags_index":"AIGC,扩散模型","author_index":"Sonderlin"},{"id":"71f02e50762204cb69b459e8f982ddf3","title":"AIGC内容安全调研","content":"调研2024ECCV——To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy to Generate Unsafe Images … For Now问题：本文针对扩散模型生成图像的有害内容安全问题，对现有的有害概念非学习（不通过重新训练或微调模型来移除模型生成不适当内容的方式）策略的有效性存疑，因此提出一种对抗性提示攻击算法UnlearnDiffatk来评估扩散模型在经过有害概念非学习后是否还会产生有害内容，来评估非学习策略的有效性，并与其他的对抗性提示攻击算法进行对比，展示UnlearnDiffatk的有效性和效率。\n2024ECCV——Reliable and Efficient Concept Erasure of Text-to-Image Diffusion Models问题：本文同样是针对扩散模型生成图像的有害内容安全问题，针对已提出的几种在扩散模型中擦除不恰当概念（遗忘）的方法往往存在擦除不彻底、计算资源消耗过多、损害正常内容的生成能力等问题，提出了一种可靠高效的擦除方法（RECE），相较其他方法效率更高、擦除更彻底、对正常内容的生成能力的负面影响更小。\n2024ICLR——To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy to Generate Unsafe Images … For Now（这篇作者相当于否认了所有模型训练后的概念移除方法）\n问题：针对扩散模型生成图像的有害内容安全问题，现有的解决方法主要分为两种：\n1.数据集预筛选（非学习）：在训练模型之前，通过剔除含有不适宜内容的数据，减少模型学到这些概念的可能性。\n2.训练后概念移除：通过训练或调整已经训练好的模型，删除模型中的特定概念。这些方法通常比重新训练整个模型更具可行性，并且许多模型的“清理”版本也被公开发布。\n作者发现了现有方法的局限性：\n1.即使在数据预处理中使用过滤器（例如NSFW过滤器），也无法完全避免模型学到不适当内容，存在较多“假阴性”（漏网之鱼）；\n2.尽管一些方法（如Erased Stable Diffusion, Unified Concept Editing）通过调整模型的权重永久删除了某些敏感概念，但在实验中作者认为这些方法并不牢固，并可能会被绕过。\n因此，作者基于其核心假设：这些概念移除方法实际上是通过某种形式的输入过滤（而非完全删除概念）来实现的。因此，概念仍然存在于模型中，只是被映射到了不同的词嵌入上，这使得这些方法易于被复杂的输入提示绕过，因此作者设计了一种攻击方法，旨在通过调整输入提示词来重新激活模型中隐藏的、被移除的概念，通过学习特定的输入词嵌入，重新激活那些“被删除”的敏感内容。\n方法目标：在没有修改模型权重的前提下，设计一个特殊的输入提示（或嵌入），从模型中生成原本已经被“移除”的概念（如名人形象、特定艺术风格、NSFW内容等）\n2024NAACL——Universal Prompt Optimizer for Safe Text-to-Image Generation本文作者针对扩散模型生成图像的有害内容安全问题，针对现有解决方案在实际应用中存在很多限制（影响用户体验、需要已知模型内部结构、缺乏实用性），提出了首个黑盒提示词优化器POSI，能够自动将不安全的文本提示转换为安全的提示，同时保持文本语义基本不变，实用性较强，能够在不需要访问T2I模型内部结构的情况下生成安全图像。POSI的核心思想是通过提示词优化，修改输入的有害提示词，使得生成的图像既安全又语义保持一致。\n2024ICLR——RING-A-BELL! HOW RELIABLE ARE CONCEPT REMOVAL METHODS FOR DIFFUSION MODELS?针对当前文本到图像扩散模型（如Stable Diffusion）中的概念移除方法的可靠性尚未得到全面检验这一问题，作者提出了\nRing-A-Bell，一种新颖的模型无关红队工具，用于评估扩散模型的安全机制。该工具不需要预先了解目标模型的结构，可以通过概念提取获取敏感和不当概念的全局表示，并基于这些表示自动生成问题提示词，以揭示模型生成不当内容的风险。\n2024【貌似是首个研究视频内容安全的】arXiv——Towards Understanding Unsafe Video Generation作者通过实验验证了现有的视频生成模型可以生成不安全内容。首先，他们从4chan和Lexica等网站上收集了大量可能生成不安全内容的提示词（prompts）。这些提示词曾用于生成不安全的图像，因此作者假设它们也可能引发视频生成模型产生不安全视频。\n他们使用三个最先进的开源视频生成模型（SOTA VGMs）来生成不安全视频，并从最初的5607个视频中挑选出2112个视频进行进一步分析。为了定义不安全视频的类型，作者通过聚类分析（k-means）和主题编码分析（thematic coding analysis）对生成的视频进行分类，最终确定了五类不安全视频：扭曲/怪异、恐怖、色情、暴力/血腥、以及政治类。\n并通过在线用户调研人工标记，从2112个视频中识别出937个被一致认为是不安全的视频，形成了首个不安全视频生成数据集。\n在实验生成数据集的基础上，作者进一步研究如何防止生成不安全的视频。他们提出了一种新的方法，称为潜变量防御（Latent Variable Defense, LVD），该方法在模型的内部采样过程中工作，可以提前终止生成不安全视频，减少计算资源的消耗。\n","slug":"AIGC内容安全调研","date":"2024-09-20T05:51:09.000Z","categories_index":"AI安全","tags_index":"AIGC安全","author_index":"Sonderlin"},{"id":"8efbfa0326f4c642fe60c9dd565aaa12","title":"Towards Understanding Unsafe Video Generation","content":"aigc视频安全：Towards Understanding Unsafe Video Generation论文摘要视频生成模型（VGMs）近年来展示了生成高质量视频内容的能力，但是它们也可能被滥用生成不安全的内容。\n研究人员从4chan和Lexica等网站收集了不安全内容的提示语，并使用三个开源的最先进视频生成模型（SOTA VGMs）生成视频，在生成的5607个视频中，经过过滤后得到2112个不安全视频。\n通过聚类和主题编码分析，研究人员将这些视频分为五类：扭曲/奇怪、恐怖、色情、暴力/血腥和政治。\n通过在线招募403名参与者对视频进行标注，最终确认了937个不安全视频，并构建了首个由VGMs生成的不安全视频数据集。\n此外，本文还提出了一种新的防御机制，称为潜变量防御（Latent Variable Defense, LVD），它通过在模型的内部采样过程中进行监控，能够以0.90的准确率防止生成不安全的视频，同时减少了计算资源的消耗。\n实验验证：LVD在三个开源视频扩散模型中的实验中表现良好，准确率分别达到了0.99、0.92和0.91。此外，LVD还可以与现有的防御机制结合，提升它们的防御效果。\n引言VGM可以用于生成不安全内容，危害类似Deepfakes，但Deepfakes主要关注于面部视频，而本文所关注的重点而是更一般的生成模型生成的视频内容，不只局限于面部视频。\n而目前，针对图像生成模型，已经有很多解决方案（概念移除等等）都表现不错，但在视频生成领域中，由于视频包含更多信息（包括空间和时间），因此检测视频的内容安全比图片更具挑战性，并且视频需要更多的计算资源来生成。本文即对其进行思考。\n针对图像生成模型的内容安全问题，现有解决方案主要分为两种：1.与模型无关的；2.调整模型的（需要修改参数或配置）。\n然而，其都有缺点，分别为：只能根据扩散过程的最终结果来限制、需要大量的计算资源。\n本文针对视频则提出了一种位于中间立场的方法，基于扩散过程中的中间结果建立了分类器进行检测，当怀疑结果不安全时，会提前终止扩散，从而节省计算资源。\n\n\n步骤一：数据集收集1.生成不安全的视频\n通过在知名的匿名平台收集了不安全内容，进行预处理后作为不安全的文本提示\n2.视频主题划分\n通过将每个视频的所有帧进行处理，提取特征后，通过kmeans算法进行聚类，得到23类，分别对应不同的类别。\n\n\n3.划分不安全视频类别\n由于目前不存在 不安全视频内容检测器，因此本文采用人工的Thematic Coding Analysis来对视频进行主题总结，最后将怪异、恐怖、色情、暴力、血腥等的主题总结为不安全视频类别，然后通过在线调查，让用户根据之前主题总结的关键词，对2112个不安全视频进行标注标签，最终本文得到了一个标注后的不安全视频数据集。\n其中有590个视频为“扭曲/怪异”，579个为“恐怖”，445个为“色情”，204个为“暴力/血腥”，39个为“政治”。\n步骤二：潜变量防御针对图像生成内容安全中的调整模型与输出过滤（模型无关）方法的缺点，提出了一种介于模型调整和输出过滤之间的方法。\n只需要对扩散模型进行读访问，并检测扩散过程中的不安全内容，即可完成防御。\n可以发现，其与 模型无关的输入输出过滤方法有相似性，但与输入过滤相比，其读取模型更具鲁棒性，与输出过滤相比，则更高效（因为不需要完成整个输出过程，中间阶段即可终止）\n此外，本方法还可与其他两种方法进行协作。\n本方法基于这样一个推测：同一类型的不安全视频是由于其在潜空间中彼此接近的潜变量来生成的。\n首先使用已标注好的不安全视频对应的各个潜变量阶段特征进行训练分类器，得到分类器，针对去噪过程中一步步去噪产生的各个中间结果利用事先训练好的多个分类器对其进行检测，根据检测的二分类结果作为评分，累计每一步的评分（加权求和），当累计评分超过阈值时，则判断该视频为不安全视频，立即终止生成。\n实验指标1.实验设置\n测试时 本文使用了三个开源的最先进视频生成模型：MagicTime、AnimateDiff 和 VideoCrafter。这些模型用于生成包含不安全内容的视频，然后通过潜变量防御机制进行检测，使用 VideoMAE 作为检测模型的主架构，将其与训练的全连接层结合，构建分类模型。\n2.模型训练\n每个视频生成模型配置了50次推理步骤（denoising steps），并为每个类别的不安全视频训练了50个不安全视频检测模型。\n3.实验指标\n准确率（Accuracy）：衡量模型正确分类（不安全视频和安全视频）的比例。该指标用于总体评估检测机制的效果。\n真实正率（True Positive Rate, TPR）：模型正确识别出不安全视频的比例，表示检测机制在不安全视频上的敏感度。\n真实负率（True Negative Rate, TNR）：模型正确识别出安全视频的比例，用来衡量模型对安全视频的区分能力。\n接收者操作特征曲线下面积（AUC-ROC）：绘制假正率（FPR）和真实正率（TPR）之间的关系曲线，用AUC值来评价模型的整体性能。AUC值越高，表示模型区分安全和不安全视频的能力越强。\n","slug":"Towards Understanding Unsafe Video Generation","date":"2024-09-20T05:51:09.000Z","categories_index":"AI安全","tags_index":"AIGC安全","author_index":"Sonderlin"},{"id":"f82ea2e25307b21f0d8395b86adf870d","title":"RECE扩散模型概念移除","content":"Reliable and Eficient Concept Erasure of Text-to-Image Diffusion Models论文概述论文讨论了文本到图像的扩散模型中涉及的安全问题，例如侵犯版权和生成不适合工作的内容（NSFW）。当前的一些方法试图消除扩散模型中的不当概念，但往往效果不彻底，且消耗大量计算资源，同时还会损害模型的生成能力。\n为了解决这些问题，论文提出了一种名为RECE（Reliable and Efficient Concept Erasure）的新方法，可以在3秒内修改模型，而无需额外的微调。RECE通过闭式解的方式高效地派生出新的目标嵌入，并将不当概念与无害概念对齐，从而彻底消除不当概念，同时尽量减少对模型生成能力的影响。\n研究现状许多方法需要对模型进行大量参数的微调，导致消耗大量的计算资源；效果不彻底，大多数方法在消除不当概念时并不完全，模型依然有可能在某些提示下生成不当内容；在消除不当概念的同时，这些方法往往会损害模型的生成能力，使其生成正常内容的能力下降。\nRECE方法为了解决这些问题，作者提出了一种可靠且高效的概念消除方法——RECE\n该方法的关键特点是：\n\n高效：RECE使用闭式解，可快速完成模型的修改，而不需要耗时的微调。\n彻底：RECE可以通过推导新嵌入，确保模型不能再通过复杂提示以绕过来生成不当内容。\n保留生成能力：为了防止对模型生成正常内容的能力产生负面影响，RECE引入了正则化项，确保删除不当概念时对模型生成其他正常图片的影响最小。\n\n方法原理：\n在扩散模型中，文本嵌入是通过交叉注意力（cross-attention）层融入图像生成过程的。通过修改这些交叉注意力层中的键值投影矩阵（Key/Value projection matrices），实现对不当概念的高效消除，并且通过解析解来实现这一修改，非常快速：这种方法只修改交叉注意力层的部分参数，因此相比其他需要大量微调的模型，更加快速和高效。\n然而，虽然此方法（UCE）可以快速消除某些概念，但它并不能彻底消除所有不当概念。RECE则进一步通过推导出能够重新生成这些被消除概念的新嵌入，来确保消除过程的彻底性。如果能得到一个新的概念嵌入，满足在编辑后的交叉注意力映射后，足够接近经过编辑前的映射值，那么应能够诱导生成NSFW图片。新嵌入的解析解如下：其中，c是原始的不当概念嵌入（例如“裸露”），通过这个公式找到新的嵌入c′，从而引导修改后的模型生成对应的图像。\n","slug":"RECE扩散模型概念移除","date":"2024-09-17T05:51:09.000Z","categories_index":"AI安全","tags_index":"AIGC安全","author_index":"Sonderlin"},{"id":"36130dfd6fe38901b54c558831ed6ce3","title":"对抗攻击篇—C&W对抗攻击Towards Evaluating the Robustness of Neural Networks","content":"C&amp;W对抗攻击—Towards Evaluating the Robustness of Neural Networks论文概述2016年提出一种蒸馏网络的防御方法（梯度屏蔽），蒸馏网络的作者声称防御蒸馏能够击败现有的攻击算法，并且将他们的攻击成功率从95%降低到5%，且可用于任何前馈神经网络。（类似于老师-学生的知识蒸馏模型）\n本文作者则对防御性的蒸馏网络提出了挑战，设计出了一种新的基于优化的对抗攻击方法。\n防御蒸馏（通过提升模型泛化性以抵抗对抗攻击）蒸馏（Distillation，或称知识蒸馏、网络蒸馏）最初不是用作于防御方法，而是一种将深层神经网络集合中的知识压缩为单一神经网络的方法，由原始网络和蒸馏网络 2 个网络组成：\n\n原始网络：教师网络，一般为参数多且结构复杂的网络；\n蒸馏网络：学生网络，一般为参数少且结构简单的网络。\n\n蒸馏可以让经过良好训练的复杂教师模型来指导较轻的学生模型的训练，以减少模型大小和计算资源，同时尽可能保持原始教师模型的准确性。这样操作的一个好处是促进了深度学习在一些资源受限，不能使用 GPUs 计算设备中的部署。\n\n\n这个做起来也很简单。训练学生网络时我们不会用到原始数据集的真实标签，而是把教师网络对输入进行预测的结果向量作为标签来训练学生网络。教室网络对一张图片的输出结果是 softmax计算得到的概率分布，我们可以认这一分布凝聚了教师网络对输入样本的理解，可以用来指导学生网络的训练，比给出一张单独标签更加高效。\n防御蒸馏不一样的地方在于：训练的两个模型架构是一样的。\n在防御蒸馏里面，softmax 的形式为：这里的 T （Temperature）是训练过程控制的一个重要超参数，称为蒸馏温度。如果我们把 T 设置成 1，就是标准的 Softmax 函数。如果 T 无穷大，输出的所有结果都是相同的， F(X) 收敛到 1/N 。因此， T 越大，输出各个类别之间的差异就会变小。\n\n\n\n\n防御蒸馏的模型结构如上图所示。第一次训练使用训练数据集 X 和原始的标签数据 Y ，称 Y 为硬标签。第二次训练，我们将第一次训练得到的结果，即概率分布 F(X) 保留下来，作为标签（称其为软标签）与 X 作为新的训练数据进行训练，得到新的概率分布。\n模型训练得到的预测概率不仅将输入X的正确分类信息编码到了网络中，同时将类别之间的相似信息也编码到了模型中，相当于对硬标签进行了平滑处理，从而提高了模型在训练数据集外的泛化性，降低对样本扰动的敏感度。而蒸馏温度 T 的设置则是更加强了这种泛化性，用较大的蒸馏温度T可以降低模型对输入变化的敏感性。不过，在预测阶段，我们需要将T设为1（即使用普通的 softmax 函数），目的是为了照顾新样本。如果在预测阶段，我们将T设置的很大，模型可能就对新样本的中的变化不那么敏感，导致误判。\n这里的T，在论文中叫Temperature，即蒸馏温度。就是一个调节的参数，通常为1，T越大，所有类的分布越（软）平缓。\nC&amp;W 攻击详解目标函数该算法将对抗样本当成一个变量，那么现在如果要使得攻击成功就要满足两个条件：\n（1）对抗样本和对应的干净样本应该差距越小越好；（2）对抗样本应该使得模型分类错，且错的那一类的概率越高越好。\n这类问题可以表述为一个约束最小化问题：\n\n 是干净样本\n 是加入的扰动\n 是距离度量（衡量干净样本  和扰动样本  之间的距离）\n 是攻击的目标标签\n 分类器\n 限制扰动使其范围固定在  之间\n\n对于距离度量  而言，我们用  表示距离， 距离常常被写作 ，其  范数被定义为：\n$$| v |p = \\left( \\sum{i=1}^{n} |v_i|^p \\right)^{\\frac{1}{p}}$$\n对于距离度量，本文选择了三种：\n\n 距离度量的是  的坐标  的数量，其对应的是图像中被改变的像素的数量。\n 距离度量的是  和  之间的欧式距离，当许多像素发生小变化时， 可以保持较小。\n 距离度量的是  和  之间最大的绝对距离，即 ，间接体现了图像中的变化像素。\n\n然而，由于 具有高度的非线性性质，所以需要选择一种更适合优化的表达方式。因此，本文定义了一个目标函数f，当且仅当时， 。\n随后针对该定义性质，本文给出了7种目标函数f的选择：\n$$\\begin{align}f_1(x’) &amp;= - \\text{loss}{F,t}(x’) + 1 \\tag{1} \\f_2(x’) &amp;= \\left( \\max{i \\neq t} (F(x’)_i - F(x’)t) \\right)^+ \\tag{2} \\f_3(x’) &amp;= \\text{softplus} \\left( \\max{i \\neq t} (F(x’)_i - F(x’)_t) \\right) - \\log(2) \\tag{3} \\f_4(x’) &amp;= (0.5 - F(x’)_t)^+ \\tag{4} \\f_5(x’) &amp;= -\\log(2F(x’)t - 2) \\tag{5} \\f_6(x’) &amp;= \\left( \\max{i \\neq t} (Z(x’)_i) - Z(x’)t \\right)^+ \\tag{6} \\f_7(x’) &amp;= \\text{softplus} \\left( \\max{i \\neq t} (Z(x’)_i - Z(x’)_t) \\right) - \\log(2) \\tag{7}\\end{align}$$\n其中， 运算表示max(e,0)；−loss 表示交叉熵损失；表示神经网络使用 x′ 作为输入，产生类别是 i 的概率；Z(x′) 表示softmax前的输出，即 F(x)=softmax(Z(x))。\n其中，效果最好的是第6个，针对第6个公式，表示除了目标错误类别 t 以外，网络以最大概率认为这是第i个类，但第i类的概率仍然低于第 t 类的概率，以此认为攻击成功，最终值为0，满足定义。f4同理，表示分类错误的概率大于0.5。因此，优化目标修改为：\n\n为了便于优化，模仿L-BFGS进行修改，转换为目标函数：\n其中，c 的选择是一个坑，如果 c→0，那么梯度下降时，损失大部分来自图像误差；如果 c 很大，那么分类损失将占主导，两者的损失应该相似。论文中，作者使用实验的方式确定了 c 的最佳取值。\n\n\n当 c&lt;1 ，攻击成功率很低。在 c&gt;1 之后，攻击效果提升不大，但Mean Adversarial Example distance（MAED）变得很大，扰动变大。\n盒约束为了确保生成有效的图片，对于像素点的扰动 δ 存在着约束，在优化问题中，这个被称为 “盒约束”。该论文研究了三种不同方法来解决这个问题：\n1.Projected gradient descent梯度投影\n在每次迭代中，执行一个单步标准梯度下降后，将所有坐标约束到的范围内。\n缺点：它将剪辑后的图片作为下一次迭代的输入，这样每次传入下一步的都不是真实像素值，让误差越来越大。\n2.Clipped gradient descent梯度截断\n将盒约束整合到目标函数中，即目标函数从转化为。\n缺点：当x很大时，取值恒为1，偏导也就是梯度恒为0，在此情况下，梯度下降无法进行。\n3.Change of variables引入新变量\n针对以上方法的缺点，本文引入了一个新的中间变量：因此对抗样本可以表示为：因为tanh的取值范围是[-1,1]，所以的取值范围是，这样就满足了盒约束。\n开始攻击1.L2攻击\n目标函数选择之前最优的：论文中令为0；\n在求解时，论文提到了多起点梯度下降方法，即通过选择多个随机起点进行梯度下降，降低陷入局部最小值的可能性，类似于智能优化算法（遗传算法、模拟退火等等），从而提升攻击速度。\n并且本文通过实验证明L2攻击效果非常好，视觉上基本无法区分攻击样本图片和原始图片。\n2.、攻击\n由于，距离度量,不连续，故不可微，无法使用梯度下降方法，所以只能进行迭代攻击，且实验结果也不是很好，感觉应该不怎么实用，没细看了。\n","slug":"C&W对抗攻击","date":"2024-09-10T13:28:09.000Z","categories_index":"AI安全","tags_index":"对抗样本","author_index":"Sonderlin"},{"id":"65cddfcfb868b3bd0465ddd01db41d3a","title":"对抗攻击4——(PGD)TOWARDS DEEP LEARNING MODELS RESISTANT TO ADVERSARIAL ATTACKS论文解读","content":"TOWARDS DEEP LEARNING MODELS RESISTANT TO ADVERSARIAL ATTACKS论文解读论文概述本文即在FGSM的基础上进行了改进，针对FGSM仅做一次迭代的缺陷（难以应对非线性的损失函数），提出了PGD迭代攻击方法，即K-FGSM（K表示迭代的次数），做K次FGSM，并使得每次的幅度更小。即从一次一大步改进为多次一小步。好像还存在L2范数归一化的变式，避免了sign没有归一化的缺点：\n$$\\mathbf{X}{t+1} = \\Pi{X+S} \\left( \\mathbf{X}_t + \\epsilon \\left( \\frac{g_t}{|g_t|} \\right) \\right)$$\n","slug":"(PGD)TOWARDS-DEEP-LEARNING-MODELS-RESISTANT-TO-ADVERSARIAL-ATTACKS论文解读","date":"2024-09-10T10:28:09.000Z","categories_index":"AI安全","tags_index":"对抗样本","author_index":"Sonderlin"},{"id":"0d2626f16e99b6aca31641a73ebbe19c","title":"对抗攻击3——Explaining and harnessing adversarial examples论文解读","content":"对抗攻击3——Explaining and harnessing adversarial examples论文解读论文概述以前的工作大多认为对抗样本的存在是由于深度神经网络的极端非线性，可能与模型纯监督学习下的过拟合、正则化不足问题有关。作者证明了这些推测是不必要的，因为作者认为神经网络容易受到对抗性扰动影响的主要原因是因为它的线性本质，并基于此提出了快速梯度符号法FGSM以及进行了相关实验。\n相关工作\nBox-constrained L-BFGS可以可靠地找到对抗样本。\n在一些数据集上，如ImageNet (Deng et al.， 2009)，对抗例子与原始例子非常接近，以至于人眼无法分辨出差异。\n同一对抗实例经常被具有不同架构的各种分类器或者在训练集的不同子集上训练的分类器错误分类。\n浅的softmax回归模型也容易受到敌对例子的影响。\n在对抗样本上进行训练可以正则化模型——然而，这在当时是不实际的，因为需要在内部循环中进行昂贵的约束优化。\n\n主要内容1.对抗样本的线性解释线性关系如何会产生对抗样本，考虑权重向量和对抗样本和对抗扰动的关系式如下：上式可以看出如果有维，且每一个权重向量的元素的均量维，那么扰动的增长便是mn线性增长的，因此对于高维的关系，即使输入加入很小的扰动，其结果也会产生较大的变化，从而解释了高维的复杂神级网络对抗样本的存在也是因为其线性本质。\n2.非线性模型的线性扰动作者认为神经网络是过于线性以至于不能抵抗线性对抗干扰，如ReLU等激活函数，为了优化计算速度，都有意地采用非常线性的形式，而这些线性行为所带来的对抗样本的脆弱性也将摧毁神经网络。\n​                                                                                       \n基于对抗样本的线性解释观点，作者提出了一种快速产生对抗样本的方法：快速梯度符号法FGSM，并进行了相关实验。\n假设是模型的参数，是输入，是输出，是神经网络的误差函数。作者通过在当前输入位置对非线性误差函数进行线性化操作（一阶泰勒展开），接着对线性化后的函数求关于输入x的梯度方向，再对其进行sign符号函数处理其分量，获取梯度的正向方向（沿梯度正向方向，损失函数值增加的最快，误差越高），再乘以常数以控制其扰动的幅度。x+即为最终得到的对抗样本\n以上作者通过实验证实，确实能够产生对抗样本，为对抗样本的线性解释提供有力的证据。\n3.线性模型的对抗训练对于逻辑回归模型，假如用其去识别标签：，其中就是逻辑sigmoid函数了。可以通过计算下面公式的梯度来训练模型：\n   应用FGSM算法，即可得到对抗版本的逻辑回归损失函数：\n4.深度网络的对抗训练​       同样是基于FGSM算法改进损失函数：​      文中实验部分作者设置=0.5\n","slug":"Explaining and harnessing adversarial examples","date":"2024-09-06T10:28:09.000Z","categories_index":"AI安全","tags_index":"对抗样本","author_index":"Sonderlin"},{"id":"68873544f6b8e969a8c85b81e08aff1b","title":"对抗攻击2——Intriguing properties of neural networks论文解读","content":"对抗攻击2——Intriguing properties of neural networks论文解读符号说明\n\n论文概要本文主要提出了两个重要的观点：\n观点一：\n关于神经网络的语义分析，以前的研究工作持有这样的观点：神经网络的语义信息独立地 (individually) 保存在每一个神经元内，特别是在最后一个隐藏层中，每一个神经元都可以作为数据的一个语义特征 (semantic feature)。以上观点可以用如下式子表述：这个表达式的意思是找到图像x‘，使得φ(x)在方向的分量最大，也就是说图像x‘最突出地反映了ei分量所在的神经元代表的语义特征。找到许多满足式子的x‘，就可以总结出单个神经元所代表的语义特征。\n而作者不再取某个神经元所在的单位方向矢量，而是取向量空间里的一个随机单位矢量v，同样找到满足式子的图像集合。作者发现，这样找到的集合同样具有相似的语义特征，得到了同样的结果\n\n\n因此得出结论：神经网络的语义特征不存在于独立的神经元中，而存在于整个神经元激活的空间内。\n观点二：\n对抗样本的产生是低概率事件。据此我们可以推断，对抗样本在训练集和测试集中都很少，模型只学到非对抗样本的特征，所以当模型遇到与输入图像看起来“无异”的对抗样本时就会表现得非常脆弱。\n此外，作者提出了一种生成对抗样本的方法，称为Box-constrained L-BFGS。\n令 f 表示已训练好的神经网络，r 表示扰动信号，l 表示希望模型最终预测得到的类别，则需要优化的问题如下：\n\n\n可以得到对应的目标函数：\n\n上面的目标函数中分为两部分，第一部分是 c|r| 这一部分限制扰动信号r不能太大；第二部分是分类的损失函数loss，通过优化这个loss可以让神经网络把样本x+r预测为l类别的概率更大。\n下面是一部分实验结果，左边是原始图片，中间是扰动信号(为了更好的展示，图中扰动信号放大了10倍)，右边是增加了扰动信号后的图片。可以看到增加扰动信号后，图片肉眼看上去没什么区别，但是模型却预测错误了。\n\n\n作者在实验中还发现了对抗攻击一些有趣的方面：对于大部分网络结构和大部分样本，都可以生成一些肉眼很难区分的对抗样本迷惑神经网络。\n对抗样本有跨模型泛化能力：对于两个超参数不同的模型 1 和模型 2 (例如层数不同，每层神经元个数不同，正则化不同等) ，用模型 1生成的对抗样本，有大部分也可以让模型 2 预测错误。\n对抗样本有跨训练集泛化能力：将训练集划分为两个不同的子集，分别训练不同的模型 1 和模型 2，用模型 1 生成的对抗样本也可以提高模型2预测错误的概率。\n","slug":"Intriguing properties of neural networks论文解读","date":"2024-09-03T05:51:09.000Z","categories_index":"AI安全","tags_index":"对抗样本,图像识别","author_index":"Sonderlin"},{"id":"74bf40f03dab2977fa471e9edf464d2c","title":"对抗攻击1——Evasion attacks against machine learning at test time论文解读","content":"对抗攻击1——Evasion attacks against machine learning at test time论文解读论文概要采用梯度下降的方法生成对抗样本，并通过不断增加攻击者的先验知识与篡改能力来检验分类器的安全性能。并以恶意PDF文件检测系统入侵为例论证对抗样本的有效性。\n对手目标：创建（修改）一个样本，使得该样本被分类器以高置信度判别错误。例如，修改一个垃圾邮件样本，目标是使得分类器判别函数的值最小。\n对手知识：针对于待攻击系统（分类器），可能包括5个方面：a) 全部或者部分的训练集；b) 每个样本的特征表示；c) 学习算法和决策函数的类型；d) 已训练好的分类器模型（例如神经网络的参数）；e) 分类器的反馈（输入一个对抗样本，经过分类器得到label）。\n对手技能：只能改变测试集，不能修改训练集。包括以下3个方面：a) 修改输入数据b) 修改特征向量c) 独立修改某些特征\n攻击策略对于被分类器判别为垃圾邮件的样本 ，我们希望通过对其进行适当修改（在不改变邮件语义的前提下），使得分类器“尽可能相信”它是正常邮件样本。数学形式为：\n\n\n显然，若g(x)为凸函数，则很容易进行求解。但在非凸情况下，通常无法求得x的全局最优解。如上图中的左上图与右上图所示，沿梯度下降方向进行求解可能会向着数据分布稀疏的方向，在这些区域时，分类器给出的结果是不确定的，因此攻击不一定可以成功。\n要想增加攻击成功的概念，我们希望梯度下降方向是正常样本的密集区域，此时x可以向正常样本最密集的区域移动，攻击最有可能成功。换一种表述方式就是希望尽可能大一些，因此我们改写之前的式子，加入密度估计项来表述密集区域，得到下式：该式的梯度下降方向如上图中的下侧图所示，梯度下降方向 向着 正常样本集中的区域。从感性的角度理解，对抗样本是在模仿正常邮件的特征，使得自己的“外衣”越来越精致以迷惑分类器。\n补充知识核密度估计（Kernel Density Estimation, KDE）核密度估计是一种非参数方法，用于估计随机变量的概率密度函数。给定一个样本数据集{x1,x2,…,xn}，核密度估计的形式为：其中：\n\n是在点x处的概率密度估计值。\n是样本数据集的大小。\n是带宽参数，控制核函数的平滑度。\n是核函数，常见的核函数包括高斯核（RBF核）等，用于衡量样本与数据集中每个点之间的相似度。\n\n","slug":"Evasion attacks against machine learning at test time论文解读","date":"2024-09-01T05:51:09.000Z","categories_index":"AI安全","tags_index":"对抗样本,逃避攻击","author_index":"Sonderlin"},{"id":"43114f1350cad18fe627afc10a1b1c7b","title":"Transcend：Detecting Concept Drift in Malware Classification Models论文阅读总结","content":"Transcend: Detecting Concept Drift in Malware Classification Models出处：USENIX Security Symposium\n时间：2017\n论文概述针对攻击者不断改良恶意软件带来的概念漂移问题，本文在模型性能下降之前就进行对退化的检测模型进行识别，从而及时完成检测模型的更新\n现有研究传统方法识别模型退化：\n\n根据模型检测完成后的准确率等指标后顾性判断\n计算测试对象在候选类别中的拟合概率\n\n解决方案Conformal evaluation（保形评估）置信度（Confidence）、可信度（Credibility）、不一致性度量都是保形评估的核心。\n不一致性度量\n\n其中评分函数AD即核心的不一致性度量函数\n本文中使用p值作为相似性的度量（P-values as a Similarity Metric）：\n\n计算式解释：\n\n\nCredibility（可信度）定义：表示样本与其被分类的类别在统计上的相似程度，即样本属于该类别的可信度。\n\n\n\n\n总结：可信度越高，则表明样本在统计上更接近被分类的类别。但存在多类别匹配的局限，即对于多个类别的p值都很高，因此引入置信度\nConfidence（置信度）定义：表示算法对给定分类决策的确信程度，即算法认为该决策正确的程度\n\n\nps：max括号中的意思是除了已选择的标签的p值，最终得到的是其他标签下的p值最大值\n决策评估\n\n如果一个算法的决策评估状态是出现高可信度且高置信度的，我们就认为这个算法在决策评估上目前还不错，出现其他情况就说明可能发生了概念漂移。\n","slug":"Transcend","date":"2024-08-30T05:51:09.000Z","categories_index":"机器学习","tags_index":"概念漂移,保形预测","author_index":"Sonderlin"},{"id":"9627999a85156d234bd83b92abfc393b","title":"Hexo博客发文/配置/管理常用指令","content":"Hexo博客发文&#x2F;配置&#x2F;管理常用指令powershellhexo init  //初始化\n\nhexo new/n (title)  //新建文章\n\nhexo generate/g  //生成静态文件\n\nhexo server/s   //启动本地服务器 进行预览\n\nhexo clean      //清理缓存，有时更改了设置需要清除缓存后才可生效\n\nhexo deploy    //将本地生成的静态文件部署到github仓库中上线","slug":"Hexo博客常用指令","date":"2024-08-28T12:14:59.000Z","categories_index":"博客管理","tags_index":"博客管理命令","author_index":"Sonderlin"},{"id":"de3a9296d5a1bb4a6f357efb2f755731","title":"Hexo博客配置时遇到的问题","content":"Hexo博客配置时遇到的问题hexo博客代码高亮失效吐血了。。。csdn真一坨XX。。。网上找了半天才发现是hexo的版本高于7.0.0时代码高亮就会失效。\nbashnpm i hexo@6.0.0 //回退版本至6.x.x后成功解决作者页下面的信息栏统计有误。。一个文章必须要先设置category再设置tags  两者才会统计生效\n新建文章时没有自带categories字段默认情况下，新创建的文章是没有 categories 和 tags 的，我们可以在根目录下的 scaffolds\\post.md 文件添加即可。这样每次新建文章，就自动有了这些参数。\nMathjax插件公式显示有点问题待解决\n代码块为c++时，+号无法正常解析导致error报错待解决\n临时方案，c++代码块都改为c\n\n","slug":"Hexo博客配置时遇到的问题","date":"2024-08-28T12:14:59.000Z","categories_index":"博客管理","tags_index":"博客配置问题","author_index":"Sonderlin"},{"id":"feee444778bd7ce32a76dc60cad27adf","title":"SHAP算法原理","content":"Shapley值1953年，Shapley值首次提出。Lloyd Shapley在论文《A Value for n-Person Games》中首次提出Shapley值。Shapley值是合作博弈论中的一个解决方案，它提供了一种在玩家之间公平分配支出的数学方法。从此成为联盟博弈论的基石，经常被用来确定团体内公平有效的资源分配策略，包括在股东之间分配利润、在合作者之间分配成本以及将功劳分配给研究项目的贡献者。然而，它与机器学习的交集要到五十年后才有。\nShapley值计算假设以下情形：已经训练了一个机器学习模型来预测公寓价格，分别有park、size、floor、car四个特征。\n某个面积为50平方米（size&#x3D;50）、位于二楼（floor&#x3D;2nd）、附近有一个公园（park&#x3D;nearby）、禁止猫咪（cat&#x3D;banned）的公寓，它预测价格为300,000欧元，你需要解释这个预测，即每个特征是如何促进预测的？当所有公寓的平均预测为310,000欧元时，与平均预测相比，每个特征值对预测的贡献是多少？\n线性回归模型的答案很简单，每个特征的贡献是特征的权重乘以特征值，但这仅适用于线性模型\npark&#x3D;nearby，cat&#x3D;banned，size&#x3D;50，floor&#x3D;2nd的特征值共同实现了300,000欧元的预测，而我们的目标是解释实际预测（300,000欧元）和平均预测（310,000欧元）之间的差异：-10,000欧元。\n答案可能是：park&#x3D;nearby贡献了30,000欧元，size&#x3D;50贡献了10,000欧元，floor&#x3D;2nd贡献了0欧元，cat&#x3D;banned贡献了-50,000欧元，这些贡献加起来为-10,000欧元，最终预测为平均预测加上该贡献之和。\n那么我们该如何计算目标公寓实例各特征的Shapley值呢？\n在下面中，我们估计了cat&#x3D;banned特征值被添加到park&#x3D;nearby和size&#x3D;50的联盟后的贡献。\n第一步，我们从数据中随机抽取另一个公寓（随机找一个floor&#x3D;1st的公寓），使用该公寓自己的floor特征值1st，模拟出park&#x3D;nearby，size&#x3D;50和cat&#x3D;banned的联盟，然后我们用这个组合（floor&#x3D;1st，park&#x3D;nearby，size&#x3D;50，cat&#x3D;banned）预测公寓的价格为310,000欧元，这个估计值取决于随机抽取的公寓的值，这称之为基线值。\n第二步，我们从联盟中删除cat&#x3D;banned，然后用该公寓的cat特征值allowed替代，我们用这个组合（floor&#x3D;1st，park&#x3D;nearby，size&#x3D;50，cat&#x3D;allowed）预测公寓的价格为320,000欧元。\n第三步，重复以上过程，floor取另一个值，直到找完，就找完了被添加到park&#x3D;nearby和size&#x3D;50的联盟后的全部贡献\n将以下全部联盟的贡献都找完，计算带有和不带有cat&#x3D;banned特征值的预测公寓价格，并计算差值来获得边际贡献，将边际贡献求出（加权）平均值，从而得出Shapley值。\n \n\n\n\n","slug":"Shapley","date":"2024-07-07T14:15:09.000Z","categories_index":"机器学习","tags_index":"SHAP","author_index":"Sonderlin"},{"id":"977ed608adc923ebbb0d8daa2e5720c8","title":"DOH隧道工具使用","content":"dns2tcp使用教程https://www.jianshu.com/p/9e8367fee777\n文件传输netcat工具安装https://blog.csdn.net/qq_50377269/article/details/135772156\n等待ns记录生效ing\n(开错端口了 开成tcp53了  重新开放udp53就可以了\ngodoh doh隧道工具https://github.com/sensepost/godoh\n","slug":"DOH隧道工具使用","date":"2024-07-07T06:05:49.000Z","categories_index":"DNS","tags_index":"DoH隧道","author_index":"Sonderlin"},{"id":"cc42225e358de83b2373cd0847dd2b15","title":"深度学习","content":"深度学习数据操作tensor为torch中的一个数据结构，可以参与运算，称为张量，即多个数值组成的数组，可能有多个维度\npythonimport torch\nx = torch.arrange(3)  #生成一个从0开始,长度为3的一维tensor\nx\nOut:tensor([0,1,2])\n    \nx.shape                #查看tensor的形状\nOut:torch.Size([3])    #形状为：一维、长度为3\n    \nX=x.reshape(3,4)       #改变一个tensor的形状 改为二维的3x4矩阵\nOut:tensor([[],\n       ....            #一个二维矩阵\n           ])\n\ntorch.cat((tensor1,tensor2),dim=0/1)       #按行或按列 合并tensor\n\n\n#torch的广播机制\n当两个tensor维度相同，但形状不一致进行运算时，两者从低到高扩展然后进行运算\n\n#torch的原地操作（以节省内存）\nZ = torch.zeros_like(Y)   #形状与Y一致，但初值为全0\nprint('id(Z):', id(Z))\nZ[:] = X + Y\nprint('id(Z):', id(Z))\n\nid(Z): 140327634811696             \nid(Z): 140327634811696            #运算后地址不变，成功原地操作\n    \n#对于可变对象，如列表、集合、字典等\nX += Y 不等同于 X = X + Y\n前者为原地操作，后者创建了新的对象（浪费了内存）\n对于不可变对象 两者等同\n\n\n#torch与numpy\nx = torch.arrange(3)\nx为一个tensor对象\nA = x.numpy()  #将一个tensor对象转换为numpy中的ndarray对象\nB = torch.tensor(A)  #将一个ndarray对象转换为tensor对象\n\na = torch.tensor([3.5])   #创建一个一维的 大小为1 的张量\na, a.item(), float(a), int(a)    #转换为python中的标量\noutput:(tensor([3.5000]), 3.5, 3.5, 3)线性代数利用代码实现一些线代中的运算\npythonimport torch\nA = torch.arange(20).reshape(5, 4)     #初始化 5x4矩阵\nA\ntensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11],\n        [12, 13, 14, 15],\n        [16, 17, 18, 19]])\nA.T                                    #获取其转置\ntensor([[ 0,  4,  8, 12, 16],\n        [ 1,  5,  9, 13, 17],\n        [ 2,  6, 10, 14, 18],\n        [ 3,  7, 11, 15, 19]])\n\n#矩阵加法\nA = torch.arange(20, dtype=torch.float32).reshape(5, 4)\nB = A.clone()  # 通过分配新内存，将A的一个副本分配给B\nA, A + B\n(tensor([[ 0.,  1.,  2.,  3.],\n         [ 4.,  5.,  6.,  7.],\n         [ 8.,  9., 10., 11.],\n         [12., 13., 14., 15.],\n         [16., 17., 18., 19.]]),\n tensor([[ 0.,  2.,  4.,  6.],\n         [ 8., 10., 12., 14.],\n         [16., 18., 20., 22.],\n         [24., 26., 28., 30.],\n         [32., 34., 36., 38.]]))\n\nA * B                        #按元素乘法  \ntensor([[  0.,   1.,   4.,   9.],\n        [ 16.,  25.,  36.,  49.],\n        [ 64.,  81., 100., 121.],\n        [144., 169., 196., 225.],\n        [256., 289., 324., 361.]])\n\n#降维操作\nx = torch.arange(4, dtype=torch.float32)\nx, x.sum()\n(tensor([0., 1., 2., 3.]), tensor(6.))\n\n#默认情况下，调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量。 我们还可以指定张量沿哪一个轴来通过求和降低维度。以矩阵为例，为了通过求和所有行的元素来降维（轴0），可以在调用函数时指定axis=0。 由于输入矩阵沿0轴降维以生成输出向量，因此输入轴0的维数在输出形状中消失。\nA_sum_axis0 = A.sum(axis=0)\nA_sum_axis0, A_sum_axis0.shape\n(tensor([40., 45., 50., 55.]), torch.Size([4]))\nA_sum_axis1 = A.sum(axis=1)\nA_sum_axis1, A_sum_axis1.shape\n(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))\n\n#求平均值\nA.mean(), A.sum() / A.numel()\n(tensor(9.5000), tensor(9.5000))\n\n#点积\ny = torch.ones(4, dtype = torch.float32)\nx, y, torch.dot(x, y)\n(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))\n\n#矩阵-向量积\nA.shape, x.shape, torch.mv(A, x)\n(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))\n\n#矩阵-矩阵乘法\nB = torch.ones(4, 3)\ntorch.mm(A, B)\ntensor([[ 6.,  6.,  6.],\n        [22., 22., 22.],\n        [38., 38., 38.],\n        [54., 54., 54.],\n        [70., 70., 70.]])\n\n#范数\nu = torch.tensor([3.0, -4.0])\ntorch.norm(u)             #L2范数：所有元素平方和的平方根\ntensor(5.)\n\ntorch.abs(u).sum()        #L1范数：所有元素的绝对值求和\ntensor(7.)微积分对矩阵进行诸如求导数等运算\n\n\n分子布局符号，以分子优先\n对矩阵求导后的形状：\n\n\n计算图理论\n\n\n由此引出反向传递：\n\n\n\n\n\n\n可以发现反向传播需要利用正向传播求导的中间结果，空间复杂度较高（因此比较占用GPU资源），计算复杂度与正向传播的代价类似，但正向传播不需要存储中间结果，空间复杂度较低，但正是由于其不存储中间结果，因此导致每次都需要重新计算，导致在实际使用时的时间复杂度太高。\n自动求导python import torch\n\nx = torch.arange(4.0)\nx\ntensor([0., 1., 2., 3.])\n\nx.requires_grad_(True)  # 等价于x=torch.arange(4.0,requires_grad=True)\nx.grad  # 默认值是None\n\n# 现在计算y\ny = 2 * torch.dot(x, x)         #内积，因此y=2x^2\ny\ntensor(28., grad_fn=&lt;MulBackward0&gt;)\n\n#接下来，通过调用反向传播函数来自动计算y关于x每个分量的梯度，并打印这些梯度。\ny.backward()      #反向传播进行求导\nx.grad            #直接访问y关于x的导数\n\nx.grad == 4 * x\ntensor([True, True, True, True])\n\nx.grad.zero_()         # 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值\n\ny = x.sum()\ny.backward()\nx.grad\ntensor([1., 1., 1., 1.])\n\n#在深度学习中 一般仅对标量进行求导\n\n# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。\n# 本例只想求偏导数的和，所以传递一个1的梯度是合适的\nx.grad.zero_()     #清空梯度\ny = x * x\n# 等价于y.backward(torch.ones(len(x)))\ny.sum().backward()\nx.grad\n\n\nx.grad.zero_()\ny = x * x\nu = y.detach()     #当做常数\nz = u * x   \n\nz.sum().backward()      \nx.grad == u        #求导时也将其当做了常数\ntensor([True, True, True, True])\n\n\n#控制流的梯度计算\ndef f(a):\n    b = a * 2\n    while b.norm() &lt; 1000:\n        b = b * 2\n    if b.sum() &gt; 0:\n        c = b\n    else:\n        c = 100 * b\n    return c\n\na = torch.randn(size=(), requires_grad=True)\nd = f(a)\nd.backward()\na.grad == d / a\ntensor(True)线性神经网络线性回归​\t\t线性回归是指目标可以表示为特征的加权和，如下面的式子，其中w代表权重，x代表某样本数据的各特征，b偏移量（所有特征为0时的值）：​       我们可以用点积形式来简洁地表达模型：其中向量x对应于单个数据样本的特征​\t\t对于特征集合X，预测值可以通过矩阵-向量乘法表示为：其中，X的每一行是一个样本，每一列是一种特征。​\t\t在开始寻找最好的模型参数（model parameters）和之前， 我们还需要两个东西：一种模型质量的度量方式；一种能够更新模型以提高模型预测质量的方法。\n损失函数​\t在我们开始考虑如何用模型拟合（fit）数据之前，我们需要确定一个拟合程度的度量。​\t损失函数（loss function）能够量化目标的实际值与预测值之间的差距。 通常我们会选择非负数作为损失，且数值越小表示损失越小，完美预测时的损失为0。 回归问题中最常用的损失函数是平方误差函数。当样本i的预测值为，其相应的真实标签为时， 平方误差可以定义为以下公式：   为了度量模型在整个数据集上的质量，我们需计算在训练集n个样本上的损失均值（也等价于求和）。   在训练模型时，我们希望寻找一组参数（w∗,b∗）， 这组参数能最小化在所有训练样本上的总损失。如下式：   我们的预测问题是最小化，由于其为凸函数，即在损失平面上只有一个临界点，所以存在参数的解析解。因此将损失关于w的导数设为0，得到解析解：\n   像线性回归这样的简单问题存在解析解，但并不是所有的问题都存在解析解。解析解对问题的限制很严格，导致它无法广泛应用在深度学习里。\n随机梯度下降即使在我们无法得到解析解的情况下，我们仍然可以有效地训练模型。 在许多任务上，那些难以优化的模型效果要更好。 因此，弄清楚如何训练这些难以优化的模型是非常重要的。\n​\t\t本书中我们用到一种名为梯度下降（gradient descent）的方法， 这种方法几乎可以优化所有深度学习模型。 它通过不断地在损失函数递减的方向\t\t上更新参数来降低误差。\n​\t\t梯度下降最简单的用法是计算损失函数（数据集中所有样本的损失均值）关于模型参数的导数（在这里也可以称为梯度）。但实际中的执行可能会非常\t\t慢：因为在每一次更新参数之前，我们必须遍历整个数据集。 因此，我们通常会在每次需要计算更新的时候随机抽取一小批样本，这种变体叫做小批量\t\t随机梯度下降（minibatch stochastic gradient descent）。\n​       在每次迭代中，我们首先随机抽样一个小批量，它是由固定数量的训练样本组成的。然后，我们计算小批量的平均损失关于模型参数的导数（也可以\t\t称为梯度）。最后，我们将梯度乘以一个预先确定的正数（即学习率），并从当前参数的值中减掉，从而将参数沿着损失函数梯度的相反方向移动（损   \t\t失函数值下降最快的方向）。\n​\t\t用下面的数学公式来表示这一更新过程（表示偏导数）：​\t\t总结一下，算法的步骤如下： \n​\t\t（1）初始化模型参数的值，如随机初始化； （2）从数据集中随机抽取小批量样本且在负梯度的方向上更新参数，并不断迭代这一步骤。\n​\t  其中（batch_size）表示每个小批量中的样本数量，称为批量大小，表示学习率。批量大小和学习率的值通常是手动预先指定，而不是通过模型训\t练得到的。 \n​\t  这些可以调整但不在训练过程中更新的参数称为超参数。\n​\t\t调参即为选择超参数的过程。超参数通常是我们根据训练迭代结果来调整的， 而训练迭代结果是在独立的验证数据集（validation dataset）上评估\t\t得到的。\n从0实现线性回归代码python# 从0开始实现线性回归代码\n%matplotlib inline\nimport random\nimport torch\nfrom d2l import torch as d2l\n\n#生成数据集\ndef synthetic_data(w, b, num_examples):  \n    \"\"\"生成y=Xw+b+噪声\"\"\"\n    X = torch.normal(0, 1, (num_examples, len(w)))      # 均值为0，方差为1，大小为：n个样本、w长度个特征\n    y = torch.matmul(X, w) + b                          # matmul函数为不支持广播机制的矩阵乘法\n    y += torch.normal(0, 0.01, y.shape)                 # 给y加一个随机噪声\n    return X, y.reshape((-1, 1))             #将y作为列向量返回\n\ntrue_w = torch.tensor([2, -3.4])\ntrue_b = 4.2\nfeatures, labels = synthetic_data(true_w, true_b, 1000)\nprint('features:', features[0],'\\nlabel:', labels[0])\nfeatures: tensor([1.4632, 0.5511])     #第一个样本的各特征值\nlabel: tensor([5.2498])                #第一个样本的标签\n# 绘制样本    \nd2l.set_figsize()\nd2l.plt.scatter(features[:, 1].detach().numpy(), labels.detach().numpy(), 1);  #绘制所有样本第一列特征与标签的散点图\n\n\n#读取数据集（用于实现小批量抽样）\ndef data_iter(batch_size, features, labels):\n    num_examples = len(features)\n    indices = list(range(num_examples))\n    random.shuffle(indices)     #打乱indices中的数字顺序\n    for i in range(0, num_examples, batch_size):\n        batch_indices = torch.tensor(\n            indices[i: min(i + batch_size, num_examples)])      #每次取规模为batch_size的一些样本\n        yield features[batch_indices], labels[batch_indices]     #多次返回\n\n batch_size = 10\nfor X, y in data_iter(batch_size, features, labels):\n    print(X, '\\n', y)\n    break\ntensor([[ 0.3934,  2.5705],\n        [ 0.5849, -0.7124],\n        [ 0.1008,  0.6947],\n        [-0.4493, -0.9037],\n        [ 2.3104, -0.2798],\n        [-0.0173, -0.2552],\n        [ 0.1963, -0.5445],\n        [-1.0580, -0.5180],\n        [ 0.8417, -1.5547],\n        [-0.6316,  0.9732]])\n tensor([[-3.7623],\n        [ 7.7852],\n        [ 2.0443],\n        [ 6.3767],\n        [ 9.7776],\n        [ 5.0301],\n        [ 6.4541],\n        [ 3.8407],\n        [11.1396],\n        [-0.3836]])\n    \nw = torch.normal(0, 0.01, size=(2,1), requires_grad=True)    #均值为0，方差为0.01的2x1随机正态向量\nb = torch.zeros(1, requires_grad=True)             #偏移量b初始化为0\n\n#定义模型\ndef linreg(X, w, b):  \n    \"\"\"线性回归模型\"\"\"\n    return torch.matmul(X, w) + b\n\n#定义损失函数\ndef squared_loss(y_hat, y): \n    \"\"\"均方损失\"\"\"\n    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\n\n#定义优化算法\ndef sgd(params, lr, batch_size): \n    \"\"\"小批量随机梯度下降\"\"\"\n    with torch.no_grad():\n        for param in params:\n            param -= lr * param.grad / batch_size\n            param.grad.zero_()\n\n#训练\nlr = 0.03\nnum_epochs = 3\nnet = linreg\nloss = squared_loss\n\nfor epoch in range(num_epochs):\n    for X, y in data_iter(batch_size, features, labels):\n        l = loss(net(X, w, b), y)  # X和y的小批量损失\n        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，才是标量。\n        l.sum().backward()  # 计算关于[w,b]的梯度\n        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数\n    with torch.no_grad():\n        train_l = loss(net(features, w, b), labels)\n        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')​\t\t\n总结：线性回归恰好是一个在整个域中只有一个最小值的学习问题。 但是对像深度神经网络这样复杂的模型来说，损失平面上通常包含多个最小值。 深度学习实践者很少会去花费大力气寻找这样一组参数，使得在训练集上的损失达到最小。 事实上，更难做到的是找到一组参数，这组参数能够在我们从未见过的数据上实现较低的损失， 这一挑战被称为泛化（generalization）。\nSoftmax回归回归可以用于预测多少的问题。 比如预测房屋被售出价格，或者棒球队可能获得的胜场数，又或者患者住院的天数。事实上，我们也对分类问题感兴趣：不是问“多少”，而是问“哪一个”。\n通常，机器学习实践者用分类这个词来描述两个有微妙差别的问题： 1. 我们只对样本的“硬性”类别感兴趣，即属于哪个类别； 2. 我们希望得到“软性”类别，即得到属于每个类别的概率。 \n这两者的界限往往很模糊。其中的一个原因是：即使我们只关心硬类别，我们仍然使用软类别的模型。\n分类标签接下来，我们要选择如何表示标签。一般的分类问题并不与类别之间的自然顺序有关。幸运的是，统计学家很早以前就发明了一种表示分类数据的简单方法：独热编码（one-hot encoding）。  独热编码是一个向量，它的分量和类别一样多。 类别对应的分量设置为1，其他所有分量设置为0。在我们的例子中，标签y将是一个三维向量， 其中(1, 0, 0)对应于“猫”、(0,1,0)对应于“鸡”、(0,0,1)对应于“狗”。\n网络架构为了估计所有可能类别的条件概率，我们需要一个有多个输出的模型，每个类别对应一个输出。\nsoftmax运算然而我们能否将未规范化的预测直接视作我们感兴趣的输出呢？ 答案是否定的。 因为将线性层的输出直接视为概率时存在一些问题： 一方面，我们没有限制这些输出数字的总和为1。 另一方面，根据输入的不同，它们可以为负值。\n为了完成这一目标，我们首先对每个未规范化的预测求幂，这样可以确保输出非负。 为了确保最终输出的概率值总和为1，我们再让每个求幂后的结果除以它们的总和。如下式：其中这里，对于所有的j总有。因此，可以视为一个正确的概率分布。 \n此外，由于softmax运算不会改变未规范化的预测之间的大小次序，只会确定分配给每个类别的概率。 因此，在预测过程中，我们仍然可以用下式来选择最有可能的类别。尽管softmax是一个非线性函数，但softmax回归的输出仍然由输入特征的仿射变换决定。 因此，softmax回归是一个线性模型（linear model）。\n损失函数通过比较真实概率与估计概率之间的区别作为损失，而交叉熵常用于衡量两个概率的区别，因此我们将其作为损失：\n对其求关于未规范化的预测的导数，我们得到：\n\n换句话说，导数是我们softmax模型分配的概率与实际发生的情况（由独热标签向量表示）之间的差异。 \n从这个意义上讲，这与我们在回归中看到的非常相似， 其中梯度是观测值和估计值之间的差异。\n多层感知机线性模型的局限线性意味着单调假设： 任何特征的增大都会导致模型输出的增大（如果对应的权重为正）， 或者导致模型输出的减小（如果对应的权重为负）。\n然而我们可以很容易找出违反单调性的例子。 例如，我们想要根据体温预测死亡率。 对体温高于37摄氏度的人来说，温度越高风险越大。 然而，对体温低于37摄氏度的人来说，温度越高风险就越低。 在这种情况下，我们也可以通过一些巧妙的预处理来解决问题。 例如，我们可以使用与37摄氏度的距离作为特征。\n但是，如何去拟合一个分类中的XOR问题（这样的问题还有很多）呢？\n\n\n显然，单线性决策边界的线性模型无法正确地将这两个类别进行拟合，而我们可以通过增加学习一条决策边界来解决这个问题，可理解为学习了两个独立的单线性分类器进行组合来解决这一问题，实现正确的分类。\n\n\n加入隐藏层实现学习多个独立的单线性分类器最后预测进行组合得到最终预测，即在模型的输出层之前再加入一层，该层被称为隐藏层（并且该层引入了非线性的激活函数），可以克服线性模型的限制，处理更复杂的函数关系。我们可以把前L−1层看作表示，把最后一层看作线性预测器。这种架构就被称为多层感知机（MLP）。隐藏层的规模是超参数之一。\n\n非线性激活函数在前文中提到引入了非线性的激活函数，为什么需要这个呢？因为，如果没有引入非线性的激活函数时，假设隐藏层仍然是对输入层做一个简单的特征加权和，那么最终会得到如下式子：\n\n\n可以发现，其仍然是一个简单的线性逻辑回归模型，因此隐藏层中必须加入非线性的激活函数对输入层的元素进行操作，从而避免退化为线性模型。\n常用的激活函数：\n          \n其中，最常用的是RELU函数，但是注意，当输入值精确等于0时，ReLU函数不可导。 在此时，我们默认使用左侧的导数，即当输入为0时导数为0。 我们可以忽略这种情况，因为输入可能永远都不会是0。\n使用ReLU的原因是，它求导表现得特别好：要么让参数消失，要么让参数通过。 这使得优化表现得更好，并且ReLU减轻了困扰以往神经网络的梯度消失问题（其他激活函数在远离0时的导数近似于0）。\n过拟合、欠拟合\n\n正则化（训练阶段使用）当模型出现过拟合问题时，可以通过正则化技术来缓解。\n对于线性回归模型，一种简单方法是通过权重向量的某个范数来度量其复杂性，避免过拟合，即保证权重向量整体比较小，最常用的方法便是将其范数作为惩罚项加到最小化损失函数的问题中。\n现在损失函数函数如下所示：使用与(3.1.10)中的相同符号， 正则化回归的小批量随机梯度下降更新如下式：根据之前章节所讲的，我们根据估计值与观测值之间的差异来更新w。 \n然而，我们同时也在试图将w的大小缩小到零。 这就是为什么这种方法有时被称为权重衰减。 我们仅考虑惩罚项，优化算法在训练的每一步衰减权重。 与特征选择相比，权重衰减为我们提供了一种连续的机制来调整函数的复杂度。 较小的λ值对应较少约束的w， 而较大的λ值对w的约束更大。\ndropout（训练阶段使用）对于缓解神经网络的过拟合，通常还有两种方法，一种是在训练数据中加入随机噪声，一种是在网络层之间加入噪声\n而dropout则正是在网络层之间加噪声的一种正则化方法\n那么如何加噪声呢？我们希望的是加入噪声后也不要改变整体原始数据的期望\n\n\n即每次训练都会随机地将隐藏层的某些节点进行丢弃，丢弃概率作为控制模型复杂度的超参数，通常取0.5\n\n\n前向传播、反向传播和计算图我们已经学习了如何用小批量随机梯度下降训练模型。 然而当实现该算法时，我们只考虑了通过前向传播（forward propagation）所涉及的计算。 在计算梯度时，我们只调用了深度学习框架提供的反向传播函数，而不知其所以然。\n梯度的自动计算（自动微分）大大简化了深度学习算法的实现。 首先，我们将重点放在带权重衰减（L2正则化）的单隐藏层多层感知机上。\n前向传播\n前向传播（forward propagation或forward pass） 指的是：按顺序（从输入层到输出层）计算和存储神经网络中每层的结果。\n我们将一步步研究单隐藏层神经网络的机制， 为了简单起见，我们假设输入样本是 x∈Rd， 并且我们的隐藏层不包括偏置项。 这里的中间变量是：其中W(1)∈Rh×d 是隐藏层的权重参数。 将中间变量z∈Rh通过激活函数ϕ后， 我们得到长度为h的隐藏激活向量：隐藏变量h也是一个中间变量。 假设输出层的参数只有权重W(2)∈Rq×h， 我们可以得到输出层变量，它是一个长度为q的向量：假设损失函数为l，样本标签为y，我们可以计算单个数据样本的损失项，根据L2正则化的定义，给定超参数λ，正则化项为其中矩阵的Frobenius范数是将矩阵展平为向量后应用的L2范数。 最后，模型在给定数据样本上的正则化损失为：在下面的讨论中，我们将J称为目标函数（objective function）。上述步骤的计算图如下：\n\n\n\n\n反向传播\n反向传播的目的是计算梯度和 从而进行梯度下降。\n因此运用链式法则，假设我们有函数和，可以计算：因此，根据计算图，反向求导，可以得到：因此，为了保证反向传播顺利进行，在前向传播时我们需要保存所有的中间计算结果，供反向传播中求导使用。\n总结\n可以理解为：前向传播为 学生做作业的过程，在作业本上写出所有的中间计算过程和结果，最后通过老师检查来判断好坏（损失函数），学生根据老师的检查结果来重新修改作业（反向传播、梯度下降算法），最后充分吸收好作业内容（多次梯度下降，模型训练完成）\n卷积神经网络全连接层到卷积层对于高维感知数据，例如照片，每张照片具有百万级像素，这意味着网络的每次输入都有一百万个维度。如果仍然使用之前多层感知机中的全连接层，即使将隐藏层维度降低到1000，这个全连接层也将有10^6×10^3=10^9个参数（每一个像素点到每一个隐藏层神经元对应一个权重参数）， 想要训练这个模型将不可实现。\n因此，卷积神经网络就此诞生\n卷积神经网络在设计时考虑了以下原则：（1）平移不变性; （2）局部性；\n首先，在最初设计卷积神经网络时，参考了多层感知机中的全连接层，只不过将输入变为二维X，随之权重W变为四维张量，输出也为二维H（隐藏层中的输出）。此外，为了后续表达形式上的简洁，我们采用了V来替代W（仅仅只是下标的替换）。$$[\\mathbf{H}]{i,j} = [\\mathbf{U}]{i,j} + \\sum_k \\sum_l [\\mathbf{W}]{i,j,k,l} [\\mathbf{X}]{k,l}\\= [\\mathbf{U}]{i,j} + \\sum_a \\sum_b [\\mathbf{V}]{i,j,a,b} [\\mathbf{X}]_{i+a,j+b}.$$其中，k,l为原始输入的维度，i,j为输出的维度，其中k=i+a,l=j+a。\n随后，在上述模仿全连接层的基础上再引入卷积神经网络最初设计时需遵循的两个原则：\n（1）平移不变性; （2）局部性；\n对于平移不变形，即为输出不依赖于图像中的位置信息，因此，实际上不依赖、的值，即$[\\mathsf{V}]{i, j, a, b} = [\\mathbf{V}]{a, b}，因此我们可以将从四维降至二维，从而减少参数个数，因此可以将原式简化成：$[\\mathbf{H}]{i, j} = u + \\sum_a\\sum_b [\\mathbf{V}]{a, b} [\\mathbf{X}]{i+a, j+b}.对于局部性，即在距离很远的区域我们不予考虑，这意味着在或的范围之外，我们可以设置。因此，可以进一步将原式改写为：[\\mathbf{H}]{i, j} = u + \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} [\\mathbf{V}]{a, b}  [\\mathbf{X}]{i+a, j+b}.$$从而得到卷积层，如上式所示，其中V被称之为卷积核或滤波器，即卷积层的权重矩阵。\n超参数：填充和步幅注意力机制","slug":"深度学习","date":"2024-01-31T05:51:09.000Z","categories_index":"深度学习","tags_index":"Pytorch","author_index":"Sonderlin"}]